[
    
    
    
        
            {
                "id": 0,
                "href": "https://schecterdamien.github.io/about/",
                "title": "About",
                "section": "",
                "date" : "2022.08.23",
                "body": "A headline Some Content\n"
            }
    
        ,
            {
                "id": 1,
                "href": "https://schecterdamien.github.io/posts/2019/http2-wireshark/",
                "title": "HTTP/2 抓包遇到的坑",
                "section": "posts",
                "date" : "2021.12.23",
                "body": " 上一篇文章介绍了http2协议相关的细节。因为是为了准备分享，所以为了尽可能直观的展示协议通信（特别是握手协商）的整个过程，还是决定准备一下小的demo然后抓包演示下。在这个过程也遇到了一些问题，耽搁了不少时间，所以记录一下整个过程\nh2c抓包 分别对HTTP2的两种建立链接的方式进行抓包（h2c和h2），先演示h2c的连接建立过程，准备的server端的代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;golang.org/x/net/http2\u0026#34; \u0026#34;golang.org/x/net/http2/h2c\u0026#34; ) // http2 h2c func main() { h2s := \u0026amp;http2.Server{} handler := http.NewServeMux() handler.HandleFunc(\u0026#34;/ping\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \u0026#34;pong\u0026#34;) }) s := \u0026amp;http.Server{ Addr: \u0026#34;:5005\u0026#34;, Handler: h2c.NewHandler(handler, h2s), } http2.ConfigureServer(s, \u0026amp;http2.Server{}) log.Fatal(s.ListenAndServe()) } 然后打开wireshark，监听本地的5005端口，使用curl请求server，这里需要指定\u0026ndash;http2使用http2协议，不然的话curl默认使用http1.1：\ncurl --http2 http://localhost:5005/ping 可以在wireshark里看到建立连接的过程：\n上图是客户端(curl)发送的http1.1的协议升级请求。这里能看到上篇文章提到的协议升级的关键的header。Connection指定header有哪些逐跳头部，Upgrade指定客户端希望升级到http2协议，HTTP2-Settings则指定了连接的初始参数。\n上图是服务端的http response。返回了Upgrade表示服务端同意升级到http2协议，然后客户端和服务端就可以使用http2通信了。\nh2c抓包遇到的问题 虽然在上文已经提到了结论：\ngo在1.6开始支持HTTP/2，这个时候只支持HTTP/2 over TLS，也就是h2。只要是TLS部署，则http库就会默认进行HTTPS/2协商，协商失败则蜕化为HTTPS/1 go在1.8开始支持 HTTP/2 server push go在1.11开始支持 HTTP/2 h2c gin目前只支持h2方式的HTTP/2，不支持h2c方式的HTTP/2 但是在一开始对于go里是怎么支持http2是不太清楚的，是在第三方库里支持还是net/http直接支持？是h2c和h2两种方式都支持还是只支持h2？google的时候很多文章又语焉不详，所以在准备一段h2c server代码的时候比较曲折。\n先是直接写了一个简单的gin的demo，然后用curl \u0026ndash;http2抓包，发现server端总是不识别升级请求，后续还是使用http1.1通信，然后找gin的文档，只是写到gin支持http2 push（那说明gin肯定还是支持http2呗，但是h2c就是无法成功），后来在gin的源码里搜索h2c，无果，看issue，找到结果了，有人提了相关pr，然后又看了几篇其他文章才明白go本身官方库net里就支持http2了，h2和h2c两种方式都支持，是在gin这一层不支持h2c。然后看到了这篇文章，改了下终于能跑一个支持h2c的server了\nh2抓包 h2是通过tls协商建立http2连接，这种方式更具有实际意义，因为h2是更提倡的也是更安全普遍的建立http2的方式，先附上server端代码：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;golang.org/x/net/http2\u0026#34; ) // http2 h2 func main() { http.HandleFunc(\u0026#34;/ping\u0026#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \u0026#34;pong\u0026#34;) }) srv := \u0026amp;http.Server{ Addr: \u0026#34;:5005\u0026#34;, } // 下面这一行代码可以省略，因为net/http会自动进行协议协商，优先选择建立http2链接 http2.ConfigureServer(srv, \u0026amp;http2.Server{}) log.Fatal(srv.ListenAndServeTLS(\u0026#34;/Users/wujinjing/projects/360/go/stack.crt\u0026#34;, \u0026#34;/Users/wujinjing/projects/360/go/stack.key\u0026#34;)) } 然后打开wireshark，监听本地的5005端口，使用curl请求server：\ncurl --http2 http://localhost:5005/ping -k 发现抓到的包是这样的：\n看不到http2连接的报文，协议也显示的是TLSv1.2，而不是http2。刚开始我一直以为是不是哪里有问题，server代码有问题或者client有问题，后来才突然想到，应用数据是被加密了，客户端和服务端两端在TLS上协商密钥加密通信，wireshark肯定就不知道TLS上应用层数据都是些什么，要想看到过程，必须要能解密流量。那么问题来了，wireshark怎么解密TLS协议之上的流量呢？\n然后又看了几篇文章（可以看看参考连接），根据TLS密钥协商的过程，wireshark想要解密TLS流量大概有两种办法，一种是拿到服务端的证书私钥，wireshark能直接用私钥解密出会话密钥，然后可以解密流量。一种是某些客户端支持把TLS握手过程中生成的密钥保存在外部文件中，可供wireshark解密使用。\n尝试第一种方式 先尝试用直接导入证书私钥的方式来解密流量，重复检查配置了好几次，发现抓到的包还是没办法解密。然后google了下，发现这种方式只对RSA算法有用，因为如果是通过 RSA 算法交换秘钥，那么客户端会加密并发送给服务端，这样只需要知道服务端的私钥就可以解密出 PreMasterSecret 值。但是目前比较主流的方式都是使用DH类算法交换密钥，而DH类算法中的 PreMasterSecret 是由服务端和客户端各自计算出来，而且没有保存到磁盘，没有通过网络传输，这样就导致无法进行解密。\n然后看了下Server Hello里服务端选择的Cipher Suite：TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256。刚好是ECDHE算法，这样的话，这种配置证书私钥的方式就失效了啊，怎么办呢，略加思索\u0026hellip;.要不指定Cipher Suite？指定成RSA方式来交换密钥不就可以了吗，然后就开始在curl的时候指定tls的Cipher Suite，结果试了好几个，发现server都不支持，tls链接建立不起来，握手都过不了，一拍脑子才想起来，curl指定的是Client HELLO的Cipher Suite，是提供给server端选择的，这样直接指定一个很可能server不支持。那要不在curl默认的Client Hello里的Cipher Suite列表里找到一个RSA密钥交换类的，然后在server端来指定这个Cipher Suite？于是又开始漫长的找go里tls源码的旅途，最后是找到了，但是折腾一番，指定了好几个，发现还是会有问题，可能这些rsa的cipher suites都在go的http2实现中都不支持了？没有细细探究，感觉此路不通了，换种方式吧\n尝试第二种方式 第二种方式是客户端把握手过程中生成的密钥保存在外部文件中供Wireshark解密使用，那最主要的便是客户端是否支持这种方式。亲测Chrom和Curl是支持的，首先在命令行export SSLKEYLOGFILE=~/tls/sslkeylog.log导入环境变量SSLKEYLOGFILE指定密钥文件的路径，然后再open Chrome，或者执行curl命令，都会自动把握手过程中的密钥都保存到这个文件中。接下来需要在wireshark里指定密钥文件：[Edit]-\u0026gt;[Preference]-\u0026gt;[Protocols]-\u0026gt;[TSL] ，准备完毕就可以开始解密抓包了，至此终于能够查看http2的h2建立连接的过程了\ntips： 补充下，最近还遇到另外一个问题，需要排查某个服务到另外一个服务的https链接问题，需要抓包查看包内容，客户端是go的代码，其实也是可以配置SSLKEYLOGFILE的，这样wireshark就可以解密抓到的https流量了\nf, err := os.OpenFile(\u0026#34;keylog.txt\u0026#34;, os.O_WRONLY|os.O_CREATE|os.O_APPEND, 0664) if err != nil { log.Fatal(err) } client := http.Client{ Transport: \u0026amp;http.Transport{ TLSClientConfig: \u0026amp;tls.Config{ KeyLogWriter: f, InsecureSkipVerify: true, }, }, } 继续抓包 配置好了curl的SSLKEYLOGFILE环境变量和wireshark的相关配置，就可以观察到以下流量\n可以看到抓到的包里出现了http2协议的包了，说明wireshark已经解密出了TLS上层流量，能识别上层协议了。再来看下h2协议协商的过程。在上文提到过，h2的协议协商是借助TLS的一个扩展协议，ALPN（Application Layer Protocol Negotiation，应用层协议协商）来进行的。从上图可以看到，首先是在TLS的Client Hello里，客户端在扩展里添加了ALPN的内容，并且在里面指定了上层协议使用h2\n后面Server Hello里，服务端在扩展里添加了ALPN相关内容，确认了后续使用h2进行通信，到此为止借助tls本身的握手机制，h2的协议协商基本完成，后面就可以正常通信了\n参考链接 https://gohalo.me/post/decrypt-tls-ssl-with-wireshark.html https://blog.wonter.net/posts/f288be00/ https://imququ.com/post/http2-traffic-in-wireshark.html "
            }
    
        ,
            {
                "id": 2,
                "href": "https://schecterdamien.github.io/posts/2019/http2/",
                "title": "HTTP/2 协议",
                "section": "posts",
                "date" : "2021.07.25",
                "body": " 用grpc很久了，但是一直都仅限于使用，对于比较深层次的细节还是缺乏了解，想找个时间好好学习下这个黑盒底下的一系列技术，最近刚好要准备一个技术分享，所以就决定分享HTTP/2协议相关的细节，因为grpc的通信就是用的HTTP/2协议，这篇文章算是对准备的HTTP/2分享的一个记录\nhttp应该大家都不陌生，目前使用最多的应该还是HTTP/1.1版本的http协议，那么HTTP/1.1到底有些什么样的问题，导致需要HTTP/2呢？主要有两点\n头阻塞：HTTP/1.1中只有收到当前请求响应后才能重用当前tcp连接发送下一次请求。虽然HTTP/1.1提出了pipeline，旨在缓解这个问题。但是一方面pipeline在复杂的网络环境下很难实现和普及，其次就算都用上了pipeline，pipeline也只是使得可以在本次响应完成之前可以发送下次请求，但响应依然要严格按照顺序返回，也就是如果前一个响应被阻塞，后边的响应将不会到来，头阻塞问题还是没有完全解决。目前客户端（比如浏览器）一般会同时打开多个tcp连接来绕开头阻塞的问题，chrome默认会打开6个tcp链接，并发请求各种类型数据。但是这就带来了一个矛盾，tcp链接越多，肯定对资源的浪费是越大的，链接越少，头阻塞的问题就会越突出 重复的未压缩头数据的传输：自HTTP/1.1之后，HTTP请求中通常带有大量ASCII编码的头部，这些头部通常大部分不会变化，需要每次请求都携带（尤其像是User Agent、Cookie这些值比较长的头部字段），会给本来就拥挤的网络带来很大的压力 除此之外还有一些问题，比如TCP 的慢启动，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度，而大量http的业务请求其实本身都只是短链接的，所以导致tcp的流控算法没有很好的应用。为此，HTTP/2的出现就很有必要了\nHTTP/2 概述 先说下HTTP/2的发展历程:\n2009年，Google提出了一项实验性的协议SPDY（读音同speedy），旨在开发者不修改当前网站实现的前提下，提高页面加载速度。SPDY提出后，Chrome、Firefox、Opera等主流浏览器先后给出了实现，很多大型网站（如Google、Twitter、Facebook等）分别提供了其对SPDY会话的实现 2012年，HTTP-WG提出了在SPDY基础上构建HTTP/2的草案 2013年给出了第一个对HTTP/2的实现，自此HTTP/2、SPDY并行发展，在客户端和服务器上进行了广泛可靠的测试 2015年，Google 宣布放弃对SPDY的继续支持，标志着HTTP/2正式登上历史舞台 那么HTTP/2有些什么特点呢：\nHTTP/2 可以让我们的应用更快、更简单、更稳定 通过有效压缩 HTTP 标头字段将协议开销降至最低，同时增加对请求优先级和服务器推送的支持 带来了大量其他协议层面的辅助实现，例如新的流控制、错误处理和升级机制 HTTP/2 没有改动 HTTP 的应用语义，而是修改了数据的格式和传输方式，只需要升级基础设施（代理、web框架等），上层的业务代码都可以不必修改而在新协议下运行 上一个HTTP版本是1.1，为什么这之后不是 HTTP/1.2呢？因为 HTTP/2 引入了一个新的二进制分帧层，该层无法与之前的 HTTP/1.x 服务器和客户端兼容，因此协议的主版本提升到 HTTP/2，且HTTP/2后HTTP协议没有小版本号了，后面直接就是HTTP3\n那HTTP/2是怎么做到加入了这么多功能和优化，但是上层业务不需要改代码呢？一切都是因为引入了一个二进制分帧层，并且HTTP/2的新特性也都是建立在这个基础之上的。这又印证了那句话，“计算机中任何问题都可以通过增加一个中间层来解决“。\n如上图，HTTP/2.0在应用层（HTTP）和传输层（TCP或者TLS）之间增加一个二进制分帧层，HTTP/2.0通信都在一个TCP连接上完成，这个连接可以承载任意数量的双向数据流，相应的每个数据流以消息的形式发送。而消息由一或多个帧组成，这些帧可以乱序发送，然后根据每个帧首部的流标识符重新组装\n这是另一张描述连接（connection）、流（stream）、消息（message）、帧（frame）关系的图，这里解释下这几个概念。\n帧（Frame）： 帧是HTTP/2通信的最小单位 请求和响应都分为首部帧和消息帧单独传输，初此之外还有一些其他的类型的帧，下面会介绍帧结构的时候会说 消息（Message）： 指逻辑上的HTTP消息，比如一次请求、一次响应等。 由一个或多个帧组成，以二进制压缩格式存放 HTTP/1 中的头部。 流（Stream）： 是一条逻辑上的连接，是TCP连接中的一个虚拟通道（每个Tcp连接会建立多个steam） 可以承载双向的消息，每个流都有一个唯一的整数标识符，帧会记录Stream 的id 不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ），因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息。同一 Stream 内部的帧必须是严格有序的。 客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。 同一个连接中的 Stream ID 是不能复用的，只能顺序递增，所以当 Stream ID 耗尽时，需要发一个控制帧 GOAWAY，用来关闭 TCP 连接 连接（Connection）： 即TCP连接 这种在一个TCP连接中划分多个逻辑链接，把所有两端的流量都集中在一个TCP连接的做法，减少了服务端的压力，虽然流量还是这么多流量，但是创建的socket会明显减少，内存占用更少，每个连接吞吐量更大。并且HTTP 性能优化的关键并不在于高带宽，而是低延迟，这种做法避免了TCP的慢启动，能更有效的利用到TCP的流控算法。\n帧结构 让我们再来看一下帧的结构，帧由帧头（Frame Header）和帧负载（Frame Payload）构成，如上是帧头的结构，帧头总共9个字节，包括帧长度、帧类型、标识位、保留位和流标识符。 其中帧长度为3个字节，表示帧负载（Frame Playload）的长度（不包括帧头9字节），这个长度的最大值通过SETTING类型的帧中携带的SETTINGS_MAX_FRAME_SIZE参数来设置。假如一个HEADERS帧不够传输所有的HEADER字段，则会把剩余的部分放到后续的CONTINUATION类型的帧来传输\n帧类型，1个字节，表示帧的类型，目前HTTP/2 总共定义了 10 种类型的帧。\n帧类型 类型编码 用途 DATA 0x0 传递HTTP包体 HEADERS 0x1 传递HTTP头部 PRIORITY 0x2 指定STREAM流的优先级 RST_STREAM 0x3 终止STREAM流 SETTINGS 0x4 初始化或修改连接或者STREAM流的配置 PUSH_PROMISE 0x5 服务端推送资源时描述请求的帧 PING 0x6 探活、兼具计算RTT往返时间 GOAWAY 0x7 优雅终止连接并通知错误 WINDOW_UPDATE 0x8 用于流控，指定窗口大小的包 CONTINUATION 0x9 传递较大HTTP头部的持续帧 TCP本身有探活的机制，为什么HTTP/2里又要重新定义一个PING的帧呢？因为TCP协议栈其实是内核里实现的，收到包后会自动ack把数据缓存到内核缓存区里，然后再复制到应用程序的进程空间，所以其实TCP的探活不能反映应用程序是否正常，可能应用程序就是因为某些原因卡住了，但是进程又没挂，ack还是正常的。所以在应用层实现一种探活机制是很有必要的。 标识位，一字节，总共可以保存 8 个标志位，用于携带简单的控制信息，这里同一位在不同类型的帧里的语义可能不太一样，目前HTTP/2总共只定义了有5种标志\n标志位 位置 含义 此标志位对哪些帧有效 ACK 0x01 表示这个帧是回复确认帧（某些帧需要接受方回复一个同样类型的确认帧） SETTINGS、PING END_STREAM 0x01 表示这个帧是这个流的最后一个帧 DATA、HEADERS END_HEADERS 0x04 表示这个帧是承载http头的最后一个帧 HEADERS、PUSH_PROMISE、CONTINUATION PADDED 0x08 表示这个帧的payload里存在padding DATA、HEADERS、PUSH_PROMISE、CONTINUATION PRIORITY 0x20 表示帧的payload里存在优先级信息相关字段 HEADERS 可以发现ACK和END_STREAM在标识位的里的位置一样，都是0x01，第一位，但是在不类型的帧里，这一位可能表示是ACK可能表示是END_STREAM。有些帧是没有定义标志位（字段还是存在的，只是为0x00），包括PRIORITY、RST_STREAM、GOAWAY、WINDOW_UPDATE这些帧\n标志位后面是1位的保留位，暂时未定义\n保留位后面是31位的流标识符，所以流标识符的最大值是 2^31，大约是 21 亿。这个值表示帧属于的流，某些帧的这个值必须为0，比如SETTINGS、PING、GOAWAY，因为这些帧并不属于任何流，是和整个连接相关的。WINDOW_UPDATE的这个值可以为0，可以不为0，为0则表示这个帧的payload描述的是整个连接的流控信息，不为0则是描述的指定的这个流的流控信息。其他类型的帧流标识符不能为0，这张图很好的描述的不同类型的帧的标志位和流标示符的情况：\n帧体则在不同类型的帧里的结构都不一样，这里不再赘述，感兴趣的可以看下参考链接\nHTTP/2特性 相比HTTP1，HTTP/2除了上面说的分帧层，HTTP/2还有如下特性：首部压缩、流优先级、服务端推送、流量控制，下面一一介绍。\n首部压缩 HTTP/1.1包含很多固定字段，比如Cookie、User Agent、Accept 等，这些字段加起来也高达几百字节甚至上千字节，HTTP/2对这些内容进行了二进制压缩，所以header在HTTP/2里不是直接可读的格式。同时因为大量请求响应报文里很多header都是重复的，这些会占用额外带宽和cpu。HTTP/2把header的字段在客户端和服务端分别给缓存了。 HTTP/2处于安全考虑，没有使用常见的压缩算法比如gzip，而是定义了一个名叫的HPACK的算法，由静态表、动态表、哈夫曼编码等方式构成，更详细的可以看下参考链接\n请求优先级 将 HTTP 消息分解为很多独立的帧之后，我们就可以复用一个连接，客户端和服务器交错发送和传输这些帧的顺序就成为关键的性能决定因素。而对于浏览器来说，这是一种用于提升浏览性能的关键功能，网络中拥有多种资源类型，它们的依赖关系和权重各不相同，比如可以定义传输HTML的流的优先级比传输图片文件的流的优先级更高，来让服务端优先传输HTML\n如上图，HTTP/2定义了每个流的依赖关系，依赖于另一个流的流是依赖流，被依赖的是父流。兄弟节点则会定一个一个权重值，这个权重是个介于1至256之间的整数，兄弟节点依靠权重来分配资源。这个模型构建了一个虚拟的流，作为所有流的祖先节点，是这个依赖树的根节点（其实就是id为0的流，当然这个流是不存在的）。流节点不能依赖自身。\n请求先级这个特性主要还是客户端用来调整服务端发送资源的顺序，比如浏览器建议服务端返回资源的优先级。但是，请求优先级只是一个建议，而不是要求，更不是保证，流优先级不保证流相对于任何其他流的任何特定处理或传输顺序。也就是说，客户端定义了流优先级，并把这个信息通过HEADERS或者PRIORITY帧传输给服务端，但是服务端会不会按照这个定义的优先级顺序来进行处理和返回，则完全没有保证，可能服务端没有实现任何和流优先级相关的功能，也可能实现了，一旦服务端实现了，就可以利用客户端给予的信息来做一些优化。\n服务器推送 服务器推送这个机制允许服务端主动向客户端在新开的流上推送一些资源，典型的场景是浏览器请求一个html页面，html里会引用css和相关图片，当服务端收到html页面的请求时，除了返回html文件，还会直接把相关的css和图片文件都返回，这样浏览器就不用请求多次再来获取html页面里引用的资源了。服务器推送在语义上等同于服务器响应一个请求，为了不改变HTTP的语义怎么来做呢，服务端会先返回一个帧作为请求，然后在一个新打开的流上，返回一个帧作为响应，大概过程是：\nPush Requests：当收到一个客户端请求时，服务端决定推送一些资源，此时服务端会发送一个PUSH_PROMISE帧给客户端，这个PUSH_PROMISE帧包含了后面返回的响应帧所在的流的id，还包含了响应的header的信息。客户端在接收到 PUSH_PROMISE帧后，它可以根据自身情况选择拒绝响应流（发送RST_STREAM帧），例如，如果资源已经位于缓存中，便可能会发生这种情况。同时这个PUSH_PROMISE在语义上视作客户端对服务端的一个请求 Push Responses：发送PUSH_PROMISE帧后，服务端会直接发送数据帧到之前PUSH_PROMISE承诺的流上，作为响应，（因为header已经在PUSH_PROMISE传输了，这里只要传输body即可）也就是这里的数据帧在语义上相当于对PUSH_PROMISE帧的一个响应 服务端推送只能由服务端进行，客户端（发起连接的一方）无法推送，也就是只能是单向的。所以在第一眼看到服务端推送这个功能时，还以为和我们常规理解的服务端推送技术一样，还想着是否在HTTP/2时代就不需要websocket了，现在看来还是不太一样，正是因为这个推送是单向的，所以还是受到了很大的限制，场景也比较有限\n流量控制 由于 HTTP/2 数据流在一个 TCP 连接内复用，TCP 流控制既不够精细，也无法提供必要的应用级 API 来调节各个数据流的传输。为了解决这一问题，HTTP/2 提供了一组简单的机制，允许客户端和服务器实现其自己的数据流和连接级流控制。\n流量控制基于WINDOW_UPDATE帧，发送者通告他们准备在 stream 流，或者整个连接上接收多少个八位字节，流量控制是定向的，发送者提供信息，接收者控制自己的速度。对于一个新的stream流和整个连接，流量控制窗口的初始值为 65,535 个八位字节。并且只有DATA帧才会受到流控的限制，因为其他帧都不大，而且也比较重要，这确保了重要的控制帧不会被流量控制阻挡。无法禁用流量控制。建立 HTTP/2 连接后，客户端将与服务器交换 SETTINGS 帧，这会在两个方向上设置流控制窗口\nHTTP/2 仅定义 WINDOW_UPDATE 帧的格式和语义。未规定发送方何时发送此帧或其发送的值，也未规定接受方如何选择发送数据包。实现方能够选择任何适合其需求的算法，也就是HTTP/2的流量控制只是定义了流控信息的交换格式，至于怎么利用这些信息来进行流控，客户端和服务端可以有不同的实现\nHTTP/2带来的一些变化 那么HTTP/2到底给我们带来了哪些改变呢？最主要的一点就是更快了，上面的请求优先级、服务端推送，流量控制其实都在某种程度上让HTTP/2的请求响应更快了，并且因为浏览器可以在一个TCP上多路复用并发请求资源，不再局限于每个域只能打开一定的TCP连接，所以不会出现请求超过这个数目的资源时，后续的请求只能阻塞等待前面的请求完成的情况。在这个网站（https://HTTP/2.akamai.com/demo）上可以感受下HTTP/1.1和HTTP/2速度的差异。除此之外，有一些HTTP/1.1里的做法在HTTP/2里就不太适用了\n域名分片：HTTP/1.x中，因为浏览器会对并发连接有限制。为了突破这个限制，通常会把请求的资源置于不同的域名下（如 shard1.example.org, shard2.example.org）。而在HTTP/2中，因为不需要新开连接来解决头阻塞问题，直接可以在一个连接上多路复用，所以这种做法没什么必要了\n雪碧图：HTTP/1.x中，为了缓解请求多个图片带来的头阻塞问题，通常采用把多个图片拼接成一个大图，然后一个请求将所有图片加载在浏览器中，然后通过css或者js将所需要的部分按需展示出来，这种做法增加了代码的复杂性，并且浏览器渲染过程中，内存需要加载更多的图片，同上，因为HTTP/2支持连接多路复用，这种做法也没必要了\n拼接js、css：类似雪碧图，拼接JavaScript、CSS的做法同样是为了减少请求数，以避免潜在的头阻塞问题\n资源内联：为了防止在请求页面后，还需要多次请求页面里引用的css和图片，有时会把css、base64编码的图片直接内连到页面里一起返回，HTTP/2的服务端推送（server push）正好解决了这个问题\n当然，HTTP/2也不是那么完美，也仍然会存在一些问题，比如\n解决了HTTP1.1的队头阻塞问题，但是TCP 的队头阻塞并没有彻底解决，HTTP/2 出现丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求 TCP 连接断掉会导致所有的Stream断掉，而在HTTP/1.1里断掉一个TCP连接影响不会这么大 这篇文章(https://www.lucidchart.com/techblog/2019/04/10/why-turning-on-http2-was-a-mistake/)描述了一个问题，因为浏览器不在像之前那样限制并发的请求（通过限制TCP连接来实现），导致服务器的压力更大，并且会出现更多毛刺现象，更多尖锐的流量，监控上的流量不像之前HTTP/1.1那么平滑，需要重新调整下负载均衡的设置（虽然HTTP2也会通过SETTING帧来设置最大的并发Stream数，但是默认是100，还是比较大） HTTP/2协议协商 对于客户端或者服务端来说，怎么确认对端是否支持HTTP/2呢？这里就要说下HTTP/2的协议协商机制。HTTP/2 使用HTTP/1.1相同\u0026quot;http\u0026quot;和\u0026quot;https\u0026quot; URI scheme。且共享相同的默认端口号: \u0026ldquo;http\u0026rdquo; 为 80，\u0026ldquo;https\u0026rdquo; 为 443。因此，对于客户端来说首先需要发现上游服务器是否支持 HTTP/2，对于 \u0026ldquo;http\u0026rdquo; 和 \u0026ldquo;https\u0026rdquo; URI，确定支持 HTTP/2 的方式是不同的。对此，RFC中定义了两个不同的标识符：\n字符串\u0026quot;h2\u0026quot;标识：表示HTTP/2使用传输层安全性(TLS)协议，在TLS上加密通信，对应https 字符串\u0026quot;h2c\u0026quot;标识：表示HTTP/2，不使用TLS，直接建立在TCP明文通信，对应http h2c的协议协商 h2c，也就是直接建立在TCP上的HTTP/2的协议协商，简单来说就是客户端会先用HTTP/1.1协议的格式开始通信，然后协商升级到HTTP/2，这依赖于HTTP/1.1的协议升级机制。HTTP/1.1（也仅限1.1版本）提供了一种特殊的机制，这一机制允许将一个已建立的连接升级成新的、不相容的协议，比如HTTP/2，比如websocket。通常来说这一机制总是由客户端发起的，服务端可以选择是否要升级到新协议。借助这一技术，连接可以以常用的协议启动（如HTTP/1.1），随后再升级到HTTP/2甚至是WebSockets，大致过程如下\n当客户端支持HTTP/2，试图升级到HTTP/2，可以先发送一个普通的请求（GET，POST等），这个请求需要添加三项额外的header：\nConnection: Upgrade // 设置 Connection 头的值为 \u0026ldquo;Upgrade\u0026rdquo; 来指示这是一个升级请求. Upgrade: h2c // 设置指定要升级的协议名称，这里就是h2c HTTP/2-Settings: \u0026lt;base64url encoding of HTTP/2 SETTINGS payload\u0026gt; // 这个header包含了base64url编码的settings帧，作为客户端的初始化配置 服务端收到请求，如果服务端不支持h2c，会忽略客户端发送的 \u0026ldquo;Upgrade 头部字段，返回一个常规的响应：例如一个200 OK，此时客户端就明白服务端不支持h2c，之后将会降级成HTTP/1.1进行通信。如果服务端支持h2c，决定升级这个连接，则会返回一个 101 Switching Protocols 响应状态码，并且原样返回Connection: Upgrade和Upgrade: h2c。并且在body里就会返回一个HTTP/2的settings帧，来初始化配置，作为服务端的连接序言，之后服务端可以和客户端开始通信了\n客户端在接收到101响应后，也必须发送一个连接序言（包括一个MAGIC帧和SETTINGS帧），然后可以开始传输其他帧，和服务端通信了\nh2的协议协商 HTTP/2 over TLS 使用 \u0026ldquo;h2\u0026quot;作为协议标识符，因为h2是建立在TLS之上，而TLS本身在握手的时候就会有一个协议协商的过程，在ClientHello中，客户端会发送自己支持的一系列协议或者算法（虽然都是和后续的TLS建立有关），然后服务端会在这其中选择一组协议或者算法来作为后续建立TLS的依据，并在ServerHello里返回。并且TLS还提供了扩展机制，借着这个扩展机制，可以在TLS握手阶段做一些额外的事情，h2的协议协商就是利用TLS的扩展机制来完成的。\nh2使用名为ALPN（Application Layer Protocol Negotiation，应用层协议协商）的TLS扩展协议进行协商。正如HTTP/2前身是SPDY协议，Goggle在当时也开发了一个名为NPN（Next Protocol Negotiation，下一代协议协商协议）的TLS扩展，这就是ALPN的前身。顾名思义，APLN就是用来在TLS里协商上层协议使用什么协议的一个扩展。在HTTP/2以及之后，上文提到的HTTP/1.1的协议升级机制就被废除了，基于TLS的应用层协议均可以通过ALPN来进行协商。 h2协商大概的过程，就是客户端TLS握手时候，会在ClientHello中带上ALPN扩展，在里面会指定客户端支持的应用层协议（一般能看到HTTP/1.1、h2、h2c三种），服务端收到后会返回ServerHello，如果不能识别ALPN，则结果里不会包括ALPN扩展，如果支持h2，则会在ALPN扩展返回h2。\nHTTP/2 协议本身并没有要求它必须基于 HTTPS（TLS）部署，但是出于以下原因，实际使用中，HTTP/2 和 HTTPS 几乎都是捆绑在一起。一方面，HTTPS可以保证数据传输的安全性，另一方面因为TLS是建立在TCP之上的，对中间节点是保密的，所以具备更好的连通性，基于HTTPS部署的新协议具有更高的连接成功率。然后最重要的，当前的主流浏览器都只支持HTTPS访问HTTP/2服务，并且很多web框架也只支持h2方式的HTTP/2请求，比如go的gin。这也是个好事，可以进一步推动大家都来使用HTTPS。\nHTTP/2的支持情况 目前HTTP/2已经很成熟了，在互联网上已经比较普及了。客户端侧，主流的浏览器都已经支持了HTTP/2，在caniuse上可以看到浏览器对HTTP/2的支持情况：\n服务端侧，nginx、haproxy等主流的反向代理也都支持了HTTP/2，很多语言的web框架也都能通过某些方式来支持HTTP/2，另外一个杀手级应用grpc就是使用HTTP/2通信的。golang对HTTP/2支持的比较早：\ngo在1.6开始支持HTTP/2，这个时候只支持HTTP/2 over TLS，也就是h2。只要是TLS部署，则http库就会默认进行HTTPS/2协商，协商失败则蜕化为HTTPS/1 go在1.8开始支持 HTTP/2 server push go在1.11开始支持 HTTP/2 h2c（因为一般是不建议使用h2c这种方式来暴露HTTP/2服务的，所以社区经过不断讨论最后才决定合并对h2c的支持） gin目前只支持h2方式的HTTP/2，不支持h2c方式的HTTP/2（看到有相关的pr，不知道未来是否会支持） 如果想让服务升级到HTTP/2，目前大概有几种方式，如果只有静态资源，比如只是静态页面，像是博客这种，可以直接托管到支持HTTP/2的cdn或者类似的托管网站上。另外一种是服务端直接支持HTTP/2，需要看下框架是否支持，如果框架支持的话其实基本不需要更改业务层代码，因为HTTP/2保持语义不变，只是传输方式改变，这些复杂的事情一般web框架都会直接给处理了，对上层暴露的接口则保持了兼容（比如在go里，官方的net库直接就支持了HTTP/2，可能已经用上了都不知道），最后一种办法则是在反向代理这一层做协议转换，比如使用haproxy，haproxy和用户侧使用HTTP/2通信，和后端服务之间则是使用HTTP/1.1通信\n下一篇文章会介绍HTTP/2抓包的过程，以及途中遇到的坑\u0026hellip;.\n参考链接 https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cn https://datatracker.ietf.org/doc/html/rfc7540 https://imququ.com/post/protocol-negotiation-in-http2.html https://halfrost.com/http2-header-compression/ https://halfrost.com/http2-http-frames-definitions/ https://zhuanlan.zhihu.com/p/359920955 https://github.com/amandakelake/blog/issues/35 "
            }
    
        ,
            {
                "id": 3,
                "href": "https://schecterdamien.github.io/posts/2019/mysql-lock/",
                "title": "mysql锁总结",
                "section": "posts",
                "date" : "2021.03.04",
                "body": " 最近做了一次和MySQL（innoDB）锁有关的技术分享，记录一下\n为了能尽量准确简洁的描述innoDB的锁机制，看了好多的文章，由于innoDB中的锁系统确实非常复杂，细节特别多，如有纰漏和谬误，还请联系改正\ninnoDB锁简介 innoDb支持多种粒度的锁，按照粒度来分，可分为表锁（LOCK_TABLE）和行锁（LOCK_REC） 一般的锁系统都会有共享锁和排他锁的分类，共享锁也叫读锁，排他锁也叫写锁。加在同一个资源上，写锁会阻塞另外一把写锁或读锁的获取，读锁则允许另外一把读锁的获取，也就是读读之间允许并发，读写或者写写会阻塞，innodb中表锁和行锁都支持共享锁（简写S）和排他锁（简写X）。\n因为innoDB支持多粒度的锁，允许表锁和行锁的并存，为了方便多粒度锁冲突的判断，innoDB中还存在一种名叫意向锁（Intention Locks）的锁。\n除此之外，还有一种特殊的表锁，自增锁，主要用来并发安全的生成自增id，一种特殊的意向锁，插入意向锁，用来防止幻读问题\n表锁 表锁，锁定的粒度是整个表，也分共享锁和排他锁。不同于行锁，表锁MySQL Server层就有实现（所以MyISAM支持表锁，也只支持表锁），innoDb则在存储引擎层面也实现了一遍表锁（后面会介绍具体结构）。\n哪些时候会触发表锁呢？在执行某些ddl时，比如alter table等操作，会对整个表加锁，也可以手动执行锁表语句：LOCK TALBES table_name [READ | WRITE]，READ为共享锁，WRITE为排他锁，手动解锁的语句为：UNLOCK TABLES，会直接释放当前会话持有的所有表锁\n有一些需要注意的地方：\n因为MySQL Server层和InnoDB都实现了表锁，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁，否则，InnoDB将无法自动检测并处理这种死锁 在用LOCK TALBES显式获取锁后，只能访问加锁的这些表，并且如果加的是共享锁，那么只能执行查询操作，而不能执行更新操作，如果获得的是排他锁，则可以进行更新操作。 开始事务时会自动UNLOCK之前的表锁，COMMIT或ROLLBACK都不能释放用LOCK TABLES加的表级锁。LOCK TALBES时会先隐式提交事务，再锁表，UNLOCK TALBES也会隐式提交事务。所以，事务中需要的表锁必须在事务开头一次性获取，无法再事务中间获取，因为不管是LOCK TALBES还是UNLOCK TALBES都会提交事务 官网上建议的表锁的使用方法：\nSET autocommit=0; LOCK TABLES t1 WRITE, t2 READ, ...; ... do something with tables t1 and t2 here ... COMMIT; UNLOCK TABLES; 实际业务中，没有特殊理由，不建议使用表锁，因为锁的粒度太大了，极大的影响并发\n意向锁 意向锁是一种特殊的表级锁，意向锁是为了让InnoDB多粒度的锁能共存而设计的。取得行的共享锁和排他锁之前需要先取得表的意向共享锁（IS）和意向排他锁（IX），意向共享锁和意向排他锁都是系统自动添加和自动释放的，整个过程无需人工干预。 主要是用来辅助表级和行级锁的冲突判断，因为Innodb支持行级锁，如果没有意向锁，则判断表锁和行锁冲突的时候需要遍历表上所有行锁，有了意向锁，则只要判断表是否存在意向锁就可以知道是否有行锁了。表级别锁的兼容性如下表：\nX IX S IS X Conflict Conflict Conflict Conflict IX Conflict Compatible Conflict Compatible S Conflict Conflict Compatible Compatible IS Conflict Compatible Compatible Compatible 可以看到，意向锁与意向锁兼容，IX、IS自身以及相互都兼容，不互斥，因为意向锁仅表示下一层级加什么类型的锁，不代表当前层加什么类型的锁；IX和表级X、S互斥；IS和表级X锁互斥。其兼容性正好体现了其作用\n自增锁 自增锁是一种特殊的表级别锁，如果一个表的某个行具有AUTO_INCREMENT的列，则一个事务在插入记录到这个表的时候，会先获取自增锁。如果一个事务持有自增锁，会阻塞其他事物对该表的插入操作，保证自增连续。innodb_autoinc_lock_mode变量定义了不同的自增算法，在MySql8.0之前默认值是1，MySql8.0之后默认值是2，具体区别参考官方文档\n行锁 Innodb中的行锁种类繁多，可以分为：记录锁（record locks）、间隙锁（gap locks）、临键锁（next-key locks），插入意向锁（insert intention locks）。行锁在逻辑上都可以看作作用于索引或者索引间隙之上，索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 很多语句都会加行锁，比如Update、Delete、Insert等操作，或者使用SELECT \u0026hellip; FOR SHARE | UPDATE [NOWAIT |SKIP LOCKED]来进行当前读（Locking Reads），其中SHARE表示加共享锁，UPDATE表示加排他锁。当要加的锁与当前行已有锁互斥时，会一直阻塞等待一段时间（innodb_lock_wait_timeout定义了等待时间）。加上NOWAIT参数则不会阻塞，会立即返回，并显示一个错误，加上SKIP LOCKED则会在结果集中跳过这些冲突的记录（慎用）。\n在不同的语句，不同的事务隔离级别下，甚至不同的索引类型下，行锁会表现成不同的形式，下面介绍这些形式\n记录锁（record locks）##### 在逻辑上，记录锁可以理解为锁定的是某个具体的索引，当SQL执行按照唯一性（Primary key、Unique key）索引进行数据的检索时，查询条件等值匹配且查询的数据是存在，这时 SQL 语句加上的锁即为记录锁\n间隙锁（gap locks） 在逻辑上，间隙锁可以理解为锁住的是索引之间的间隙，是一个左开右开的区间。当SQL执行按照索引进行数据的检索时，查询条件的数据不存在，这时SQL语句加上的锁即为间隙锁。\n如上图，因为这些语句查询的值都不存在，所以锁住的都是间隙。并且在 InnoDb 存储引擎里，每个数据页中都会有两个虚拟的行记录，用来限定记录的边界，分别是：Infimum Record 和 Supremum Record，Infimum 是比该页中任何记录都要小的值，而 Supremum 比该页中最大的记录值还要大，这两条记录在创建页的时候就有了，并且不会删除。所以当查询的值比当前已有记录最大值还大时候，锁住的会是最大值到Supremum之间的间隙。比如第一条语句，查询的时候就算是等值匹配，只要这个不存在的数据落在两个索引节点之间，就算不是一个范围，也会锁住索引节点间的所有数据即gap3，范围（7，11）。\n间隙锁是可以共存的，共享间隙锁与独占间隙锁之间是没有区别的，两者之间并不冲突。其存在的目的都是防止其他事务往间隙中插入新的纪录，故而一个事务所采取的间隙锁是不会去阻止另外一个事务在同一个间隙中加锁的\n间隙锁是设计用来防止幻读的，当锁定一个gap时，其他事务没有办法再往这个gap中插入数据，PostgreSQL没有这种机制，所以PostgreSQl没有办法锁住不存在的行，无法防止幻读（见之前的文章：记一次并发问题的排查与PostgreSQL的事务隔离和MVCC）\n临键锁（next-key locks）##### 在逻辑上，临键锁可以理解为锁住的是索引本身以及索引之前的间隙，是一个左开右闭的区间。当SQL执行按照非唯一索引进行数据的检索时，会给匹配到行上加上临键锁。\n如上图，当执行select * from table_name where id = 3 for update时会锁定（-∞，3）区间，因为按照这个SQL的语义，即是为了锁住id=3的数据，不允许其他操作，如果只是锁住记录本身，肯定是没有办法保证的，因为这是非唯一索引，还有可能插入其他id=3的数据，如果把间隙都给锁住，则其他对这个间隙的插入操作都会被阻塞，从而保证了一致性，这也是临键锁的用意。\n如果加锁时，查询条件没有命中索引（非ICP的查询），则InnoDB会尝试给全表每一条记录都加上临键锁，效果相当于锁表了\n插入意向锁（insert intention locks）##### 插入意向锁是一种间隙锁形式的意向锁，在真正执行INSERT操作之前设置。当执行插入操作时，总会检查当前插入操作的下一条记录（已存在的主索引节点）上是否存在锁对象，判断是否锁住了gap，如果锁住了，则判定和插入意向锁冲突，当前插入操作就需要等待，也就是配合上面的间隙锁或者临键锁一起防止了幻读操作。\n因为插入意向锁是一种意向锁，意向锁只是表示一种意象，所以插入意向锁之间不会互相冲突，多个插入操作同时插入同一个gap时，无需互相等待，比如当前索引上有记录4和8，两个并发session同时插入记录6，7。他们会分别为(4,8)加上GAP锁，但相互之间并不冲突。\nINSERT语句在执行插入之前，会先在gap中加入插入意向锁，如果是唯一索引，还会进行Duplicate Key判断，如果存在相同Key且该Key被加了互持锁，则还会加共享锁，然后等待（因为这个相同的Key之后有可能会回滚删除，这里非常容易死锁）。等到成功插入后，会在这条记录上加排他记录锁。\n行锁小结 行锁在不同的语句中和环境条件下可以表现成：记录锁（record locks）、 间隙锁（gap locks）、临键锁（next-key locks）和插入意向锁（insert intention locks）。记录锁锁住具体的记录，间隙锁锁住记录之间的间隙，临键锁锁住记录和记录前面的间隙，插入意向锁则是特殊的间隙锁，在插入前判断行将要插入的间隙是否会有冲突。\n以上说的各种行锁的加锁情况都是在可重复读（REPEATABLE READ）隔离级别下，这个级别也是innoDB默认的事务隔离级别，是最常用的隔离级别，但是其实不同语句在不同隔离级别下加锁的情况会有非常大的区别，以下会简单说明\n不同语句和隔离级别对加锁的影响 这里先排除读未提交（READ UNCOMMITTED）这种隔离级别的情况，这种级别在生产上几乎无法使用，会出现脏读的情况，不一致读，无法保证事务的ACID。然后先看下串行化（SERIALIZABLE）隔离级别\n串行化隔离级别和可重复读隔离级别最大的区别应该是，innoDB会隐式的转换所有的SELECT语句，给其加共享锁，变成SELECT ... FOR SHARE，这样读操作会阻塞其他写操作，使得读写无法并发，只能串行，从而保证严格的一致性。不过这种行为也受到autocommit变量的影响：\n如果禁用了autocommit，如上所述，则innoDB会隐式的转换所有的SELECT语句，给其加共享锁 如果开启了autocommit，不会进行隐式转换，因为每条语句构成一个事务，所有快照读语句（也就是没有FOR UPDATE|SHARE的SELECT语句）可以被认为是只读的事务，是可以安全并发，不需要阻塞其他事务 不可重复读（READ COMMITTED）隔离级别下，和可重复读隔离级别在行锁方面主要的区别是\n不可重复读隔离级别下取消了间隙锁，临键锁也退化成了记录锁。间隙锁定和临键锁仅用于外键约束检查和重复键检查，也就是说加锁时，如果没有符号条件的查询并不加锁，有符合条件的查询也只会给记录加上记录锁。因为没有了间隙锁，所以会出现幻读问题。 在可重复读隔离级别下，加锁时如果查询条件没有命中索引（非ICP的查询），则会给表中每条记录都加上临键锁。而不可重复读隔离级别下因为没有间隙锁，则会退化成给表中每条数据加上记录锁，并且还会把没有匹配的行上的锁给释放掉，而不是把全表所有记录不管有没有匹配都给锁上 死锁 因为使用表锁时，需要一次性申请所有所需表的锁，所以在只使用表锁的情况下不会出现死锁，一般出现死锁的情况都是行锁。innoDB有死锁探测机制，在申请锁的时候，都会先进行死锁判断，采用的算法深度优先搜索，并且如果在搜索过程中发现有环，就说明发生了死锁，为了避免死锁检测开销过大，如果搜索深度超过了 200（LOCK_MAX_DEPTH_IN_DEADLOCK_CHECK)也同样认为发生了死锁。出现死锁时，innoDB会选择一个回滚代价比较小的事务进行回滚。以下会举几个比较典型的死锁例子(均在可重复度隔离级别下)，首先会先建一张测试的表：\nCREATE TABLE `student` ( `id` int NOT NULL, `uuid` varchar(64) NOT NULL, `name` varchar(64) NOT NULL, `age` int NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uuid_index` (`uuid`), KEY `name_index` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci 死锁例一 语句顺序\\事务 事务一 事务二 T1 begin; begin; T2 select * from student where id = 1 for update; select * from student where id = 2 for update; T3 select * from student where id = 2 for update; T4（死锁发生） select * from student where id = 1 for update; 这是最简单最典型的死锁的情况了，两个事务互相锁定持有资源，并且等待对方的资源，最后形成一个环，死锁出现。最后某个事务回滚，写业务代码的时候，应该对并发条件可能出现这种情况的语句有所警觉。\n死锁例二 前提：事务开始时，student表里有id=1的记录\n语句顺序\\事务 事务一 事务二 T1 begin; begin; T2 select * from student where id = 1 for share; select * from student where id = 1 for share; T3 update student set name = \u0026lsquo;Tom\u0026rsquo; where id = 1; T4（死锁发生） update student set name = \u0026lsquo;Jack\u0026rsquo; where id = 1; 两个事务分别对某个记录申请共享锁，因为共享锁性质，两个事务都能获取到。然后又都对这条记录申请排他锁，T3中事务一申请排他锁，等待事务二的共享锁释放，加入锁等待队列，T4中事务二又申请排他锁，于是形成环，死锁条件达成。所以在事务开始时就要想到后面可能会做的操作，提前获取足够强度的锁，而不是中途升级。\n死锁例三 前提：事务开始时，student表里没有id=100的记录\n语句顺序\\事务 事务一 事务二 T1 begin; begin; T2 select * from student where id = 100 for update; select * from student where id = 100 for update; T3 insert into student values (100, \u0026lsquo;uuid100\u0026rsquo;, \u0026lsquo;jack\u0026rsquo;, 18); T4（死锁发生） insert into student values (100, \u0026lsquo;uuid100\u0026rsquo;, \u0026lsquo;jack\u0026rsquo;, 18); 如上，在可重复读隔离级别下，如果两个事务同时对某个间隙用SELECT...FOR UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。因为在记录真正插入之前会加插入意向锁，插入意向锁和间隙锁互斥，所以在T3时，事务一阻塞了，申请插入意向锁排队等待事务二的间隙锁释放，T4时，事务二又申请插入意向锁，需要等待事务一的间隙锁释放，形成环，死锁条件达成。 这种情况一般发生在，某些业务需要提前锁住间隙，防止并发插入同一数据（关键属性相同的数据），也就会先SELECT...FOR UPDATE再INSERT，但是这样很容易死锁，可以直接对关键属性建立唯一索引，防止并发插入，也存在无法建立索引的情况记一次并发问题的排查，这时候可以考虑其他办法\n死锁例四 前提：事务开始时，student表里没有uuid=uuid100的记录\n语句顺序\\事务 事务一 事务二 事务三 T1 begin; begin; begin; T2 insert into student values (100, \u0026lsquo;uuid100\u0026rsquo;, \u0026lsquo;jack\u0026rsquo;, 18); T3 insert into student values (101, \u0026lsquo;uuid100\u0026rsquo;, \u0026lsquo;jack\u0026rsquo;, 18); insert into student values (102, \u0026lsquo;uuid100\u0026rsquo;, \u0026lsquo;jack\u0026rsquo;, 18); T4（死锁发生） rollback; 这也是MySql官方文档给出的一个例子。三个事务同时插入一条某个唯一索引属性（上面的uuid）相同的数据，其中某个事务先一步插入，其他两个事务会阻塞等待，然后先一步插入的事务回滚，其他两个事务出现死锁，其中某个事务会被回滚。官方文档还提到了另外一种类似的情况，具体可以参考 Locks Set by Different SQL Statements in InnoDB 这种死锁的原因是，INSERT的时候，会对唯一索引进行Duplicate Key判断，如果唯一键冲突，则会加共享锁等待，也就是T3时候的事务二和事务三，都会获得共享锁。T4时，事务一回滚，事务二和事务三都会申请升级排他锁，这样就造成类似死锁案例二的情况，形成死锁了\n死锁例五 语句顺序\\事务 事务一 事务二 T1 begin; begin; T2(死锁发生) update student set age = age + 1 where name = \u0026lsquo;jack\u0026rsquo;; update student set name = \u0026lsquo;bob\u0026rsquo; where id \u0026gt; 100; 这个例子引用自淘宝数据库内核月报-InnoDB 事务锁系统简介，这个地方的死锁我没有试出来，需要在高并发环境才可能出现，理论上可能会出现。虽然只是两个很简单的更新语句，但是事务一的加锁顺序是，先锁二级索引name_index，再锁聚集索引，事务二的加锁顺序是，先锁聚集索引，再锁二级索引name_index，不同的加锁顺序在并发时可能导致死锁\n死锁小结 使用SHOW ENGINE INNODB STATUS语句可以看到最近一次的死锁信息，在调试的时候很有帮助。\n出现死锁后某个事务会回滚，其他事务成功，上层业务会捕获到死锁错误，再重试一般会成功，如果出现大量锁重试，则说明哪里出了问题，写代码的时候可以注意以下几点可以减少死锁出现的概率：\n类似的业务逻辑尽量以固定的顺序访问表和行 如果业务允许，大事务拆小，大事务持有锁的时间更长，更容易出现死锁 为表添加合理的索引，可以看到可重复读级别下，如果不走索引（非ICP的查询）将会为表的每一行记录加锁 尽量少用for share或者for update语句，虽然看起来只是在一行记录上加锁，但是由于间隙锁和临键锁的存在，锁住的可能不止是一行记录 提前申请足够强度的锁，不要先用for share锁住行，后面再update，很容易死锁 锁的内部表示 在innoDb内部中，用unsigned long类型表示锁的类型，其中不同的位代表锁不同的信息，最低的4位表示lock_mode，中间的4位表示lock_type，其余高位表示record_lock_type，内部使用位操作来设置和判断是否设置了对应的值 ：\nrecord_lock_type lock_type lock_mode lock_mode：描述了锁的基本类型，分为以下几种\nLOCK_IS: 意向共享锁 LOCK_IX: 意向排他锁 LOCK_S: 共享锁 LOCK_X: 排他锁 LOCK_AUTO_INC: 自增锁 在源码中有一个lock_mode的枚举类型，除了以上还有几个值：LOCK_NONE，用来表示一致性读，LOCK_NUM用来表示lock_mode的数量，LOCK_NONE_UNSET用来复位低8位\nlock_type：占用中间的4位，目前只用到了5位和6位，分别表示表锁（LOCK_TABLE）和 行锁（LOCK_REC）\nrecord_lock_type：对于表锁类型来说都是空的，对于行锁目前值有：\nLOCK_WAIT：表示正在等待锁 LOCK_ORDINARY：表示临键锁 LOCK_GAP：表示间隙锁 LOCK_REC_NOT_GAP：表示记录锁 LOCK_INSERT_INTENTION：表示插入意向锁 LOCK_CONV_BY_OTHER：表示锁是由其它事务创建的(比如隐式锁转换) 以上说的是锁的类型的表示，行锁、表锁类型相关信息都统一到一个字段了。同类型字段一样，行锁、表锁本身在innoDb中也统一用一个结构体来表示lock_t，大体如下：\nstruct lock_t { trx_t* trx; // 锁所属的事务 UT_LIST_NODE_T(lock_t) trx_locks; // 事务所持锁的列表 ulint type_mode; // 锁类型 hash_node_t hash; // 全局锁哈希表对应的节点 dict_index_t* index; // 行锁的行记录索引 union { lock_table_t; // 表锁 lock_rec_t rec_lock; // 行锁 } un_member; // 锁详情 }; 行锁和表锁都用一个lock_t结构来表示，差异部分在一个union结构中表示，里面的type_mode即是上面介绍的锁类型，行锁的结构如下：\nstruct lock_rec_t { ulint space; // 锁的space id ulint page_no; // 锁的page number ulint n_bits; // 锁住位置的bitmap }; 通过（space,page_no）可以确定锁所在的页，innoDb内部还会有个字段heap_no来表示记录在页上的偏移，也就是说三元组（space,page_no,heap_no）可以唯一的确定一行的位置。在分配lock_rec_t结构的时候，还会为其在最后分配一个大小为n_bits的bitmap，而记录偏移的bit即为heap_no，用来快速判断这页哪些记录加了锁。\ninnoDb所有的行锁会插入到一个全局hash表（lock_sys-\u0026gt;rec_hash）中，相同(space,page_no)也就是同一页的锁会被Hash到同一个bucket里，通过lock_t-\u0026gt;hash串成链表。\n总结一下，就是同一事务，同一类型的行锁在同一页上会复用同一个锁结构lock_t，用后面的bitmap来具体表示锁哪些行，大大节约了空间。同一页上不同的事物或类型的锁通过链表串起来放在rec_hash的同一个bucket里，利用hash的结构先定位到页，然后遍历同一页上不同的lock_t，就可以得到哪些事物的哪些锁锁住了哪些行，这种设计平衡了时间和空间的效率。\n总结 innoDB锁系统配合MVCC机制一起实现了事务的一致性和隔离性，innoDB中的锁总类繁多，并且和事务隔离级别关系密切，不同语句在不同隔离级别下的加锁情况大有不同，细节尤其多，而了解这些对排查死锁会有很大的帮助。行锁在innoDB中的实现也颇为巧妙，值得学习\n参考链接 https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html http://mysql.taobao.org/monthly/2017/12/02/ http://mysql.taobao.org/monthly/2016/01/01/ http://mysql.taobao.org/monthly/2018/05/04/ https://www.aneasystone.com/archives/2017/12/solving-dead-locks-three.html https://www.cnblogs.com/jojop/p/13982679.html "
            }
    
        ,
            {
                "id": 4,
                "href": "https://schecterdamien.github.io/posts/2019/pg-mvcc/",
                "title": "PostgreSQL的事务隔离和MVCC",
                "section": "posts",
                "date" : "2019.04.25",
                "body": " 因为之前遇到的并发问题，所以又把pg的事务隔离和mvcc实现温习了一遍，稍微整理，遂有此文。\n数据库并发问题 说到事务隔离，得先说说数据库可能产生的几种并发问题：\n脏读（Dirty Read）：一个事务a读到了事务b更新未提交的数据，b回滚了，a读到的数据就是脏数据 不可重复读（NonRepeatable Read）：事务a多次读取同一个数据，事务b在a多次读取的过程中，对这条数据做出了更改并提交，导致事务a在多次读取结果不一致 幻读（Phantom Read）：事务a在批量更新一个表，事务b这个时候插入了一条不同的记录，导致事务a在改完后发现还有一条记录没有改，就像幻觉一样 不可重复读和幻读很容易混淆，其实幻读是不可重复读的一种特殊情况，只不过不可重复读侧重于修改，幻读侧重于新增或删除，解决不可重复读的问题只需要锁住满足条件的行，解决幻读需要提高事务的隔离级别，但与此同时，事务的隔离级别越高，并发能力也就越低。所以，所以还需要权衡。\n事务隔离级别 为了有效保证并发读取数据的正确性，提出的事务隔离级别：\n未提交读（Read Uncommitted）：允许脏读，也就是可能读取到其他事务中未提交的修改 提交读(Read Committed)：只能读取到其他事务已经提交的数据。PostgreSQL、Oracle等多数数据库默认都是该级别 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 在SQL标准中，定义了不同隔离级别会出现的并发问题：\n隔离级别 脏读 不可重复读 幻读 未提交读 可能 可能 可能 已提交读 不可能 可能 可能 可重复读 不可能 不可能 可能 串行读 不可能 不可能 不可能 注意，这是ANSI SQL标准中的定义，但是具体到数据库的实现可能不一样，只会更严格。比如Read Uncommitted这种隔离级别，其实在实际使用中是没有意义的，设置这种级别还不如用Nosql，所以在pg 中其实Read Uncommitted和Read Committed是一样的。\n关于Repeated Read，因为在同一个事务内查询到的数据都是在开启事务后第一次查询时候的快照，可知在业务层开启事务后，事务内所有的乐观锁机制都将失效，毕竟都读不到其他事务的提交了，一定会造成写冲突。除此之外，看了不少的讲pg的事务隔离的文章，都是说pg的Repeated Read不会出现幻读\u0026hellip;然后实际上，自测发现并不能完全避免。因为幻读其实分为好多种，在《A Critique of ANSI SQL Isolation Levels》论文就定义了好多种的幻读。可以说，pg的Repeated Read基于其MVCC的实现可以避免一部分，但是是无法完全避免的。 关于Serializable，pg在9.1之前，是没有Repeated Read这个隔离级别，只有Serializable。9.1之后，才把之前的Serializable重命名为Repeated Read，然后加上一个更为严格的Serializable隔离级别。在这两个隔离级别下，如果两个不同事务中同时修改一条记录都会导致其中某个事物写失败，所以在应用层需要有重试机制。 关于两者的不同，应该是说Serializable这种隔离级别可以解决更多的幻读问题，Serializable使用谓词锁（Predicate Lock）来防止这些幻读，意思是如果一个事务T1正在执行一个查询，该查询的的WHERE子句存在一个条件表达式E1，同时这个查询下面还有其他更新或者插入操作，那么另外一个事务T2 就不能插入或删除任何满足E1的数据行。比如之前遇到的并发问题，其实可以简单表达为(伪代码)：\nif not Binding.objects.filter(sku_code=\u0026#39;test\u0026#39;).all(): # 这里只有用all()才能触发pg的谓词锁，first()，exist()都不行 Binding.objects.create(sku_code=\u0026#39;test\u0026#39;) 如果是在Repeated Read下，可能就重复创建两条sku_code=\u0026lsquo;test\u0026rsquo;的Binding了，但是在Serializable里面因为存在读写依赖，并发两条事务中肯定会又一条会失败，会提示\u0026rsquo;could not serialize access due to read/write dependencies among transactions\u0026rsquo;错误\nMVCC常用实现方法 对于以上的事物隔离级别数据库应该怎么来实现呢。早期有通过用复杂的锁来实现的，最终也只是实现一部分，无法避免所有的并发问题，而且用锁来实现，会影响数据库的并发性能。对如今大部分的主流数据库，都是使用 MVCC(Multi-Version Concurrency Control)多版本并发控制来实现，达到并发并能和隔离性的完美平衡。 MVCC的基本思想是写数据时，旧的数据作为旧版本并不删除，并发的读还能读到旧版本的数据，这样读和写就可以并发了。一般MVCC有2种实现方法：\n写新数据时，把旧数据转移到一个单独的地方，如回滚段(undo log)中，其他人读数据时，从回滚段中把旧的数据读出来，如Oracle数据库和MySQL中的innodb引擎。 写新数据时，旧数据不删除，而是把新数据插入。PostgreSQL就是使用的这种实现方法。 两种方法各有利弊，相对于第一种来说，PostgreSQL的MVCC实现方式优势在于：\n无论事务进行了多少操作，事务回滚可以立即完成 数据可以进行很多更新，不必像Oracle和MySQL的Innodb引擎那样需要经常保证回滚段不会被用完，也不会像oracle数据库那样经常遇到“ORA-1555”错误的困扰 相比InnoDB和Oracle，PostgreSQL的MVCC缺点在于：\n旧版本的数据需要清理。当然，PostgreSQL 9.x版本中已经增加了自动清理的辅助进程来定期清理（VACCUM） 旧版本的数据可能会导致查询需要扫描的数据块增多，从而导致查询变慢 PostgreSQL的MVCC实现 PG为了实现MVCC，表上面会有一些系统的隐藏字段（InnoDB类似），在每个tuple(其他数据库的Row)上，会有t_xmin，t_xmax，cmin和cmax，ctid，t_infomask这些字段。其中：\nt_xmin：存储的是产生这个元组的事务ID，可能是insert或者update语句 t_xmax：存储的是删除或者锁定这个元组的事务ID t_cid：包含cmin和cmax两个字段，分别存储创建这个元组的Command ID和删除这个元组的Command ID（为了标志同一个事物内语句的先后顺序） t_ctid存储用来记录当前元组或新元组的物理位置 由块号和块内偏移组成 如果这个元组被更新，则该字段指向更新后的新元组 这个字段指向自己，且后面t_heap中的xmax字段为空，就说明该元组为最新版本 t_infomask存储元组的xmin和xmax事务状态，t_infomask只有16位，所以最多存储16种独立的状态标志，以下是t_infomask每位分别代表的含义： #define HEAP_HASNULL 0x0001 /* has null attribute(s) */ #define HEAP_HASVARWIDTH 0x0002 /* has variable-width attribute(s) 有可变参数 */ #define HEAP_HASEXTERNAL 0x0004 /* has external stored attribute(s) */ #define HEAP_HASOID 0x0008 /* has an object-id field */ #define HEAP_XMAX_KEYSHR_LOCK 0x0010 /* xmax is a key-shared locker */ #define HEAP_COMBOCID 0x0020 /* t_cid is a combo cid */ #define HEAP_XMAX_EXCL_LOCK 0x0040 /* xmax is exclusive locker */ #define HEAP_XMAX_LOCK_ONLY 0x0080 /* xmax, if valid, is only a locker */ /* xmax is a shared locker */ #define HEAP_XMAX_SHR_LOCK (HEAP_XMAX_EXCL_LOCK | HEAP_XMAX_KEYSHR_LOCK) #define HEAP_LOCK_MASK (HEAP_XMAX_SHR_LOCK | HEAP_XMAX_EXCL_LOCK | \\ HEAP_XMAX_KEYSHR_LOCK) #define HEAP_XMIN_COMMITTED 0x0100 /* t_xmin committed 即xmin已经提交*/ #define HEAP_XMIN_INVALID 0x0200 /* t_xmin invalid/aborted */ #define HEAP_XMIN_FROZEN (HEAP_XMIN_COMMITTED|HEAP_XMIN_INVALID) #define HEAP_XMAX_COMMITTED 0x0400 /* t_xmax committed即xmax已经提交*/ #define HEAP_XMAX_INVALID 0x0800 /* t_xmax invalid/aborted */ #define HEAP_XMAX_IS_MULTI 0x1000 /* t_xmax is a MultiXactId */ #define HEAP_UPDATED 0x2000 /* this is UPDATEd version of row */ #define HEAP_MOVED_OFF 0x4000 /* moved to another place by pre-9.0 * VACUUM FULL; kept for binary * upgrade support */ #define HEAP_MOVED_IN 0x8000 /* moved from another place by pre-9.0 * VACUUM FULL; kept for binary * upgrade support */ #define HEAP_MOVED (HEAP_MOVED_OFF | HEAP_MOVED_IN) #define HEAP_XACT_MASK 0xFFF0 /* visibility-related bits */ 同时，每个事务都有自己的id，事务id是一个32位的无符号整数。有3个特殊的事务id。\n0代表invalid事务号，无效的事务ID 1代表bootstrap事务号，系统表初始化的事务ID 2代表frozon事务。frozon transaction id比任何事务都要老 可用的有效最小事务ID为3，然后开始递增。同时，事务的状态会保存在Commit log里面，简称clog，事务状态有以下4种：0x00：表示事务正在进行，0x01：事务已提交，0x02：事务已回滚，0x03：子事务已提交。\n这些隐藏字段具体到每个操作的变化：\n插入数据的时候，插入的tuple的t_xmin就是当前的事务id，t_xmax为0，t_ctid保存的是当前tuple的物理位置，t_infomask为HEAP_XMAX_INVALID。如果提交，则t_infomask增加HEAP_XMIN_COMMITTED标志位，如果回滚，则t_infomask增加HEAP_XMIN_INVALID标志位。 删除数据的时候，删除的tuple的t_xmax为当前事务ID，t_infomask去掉HEAP_XMAX_INVALID，说明此时t_xmax有效。如果提交，t_infomask加上HEAP_XMAX_COMMITTED，删除有效。如果回滚，则又加上HEAP_XMAX_INVALID，说明这个删除事务无效，但是t_xmax还是当前事务id，这里主要基于性能考虑，可以直接考t_infomask来判断事务状态即可，没必要再把t_xmax刷回0。 更新数据的时候，会产生一个新的tuple，同时把那个旧tuple的t_xmax改为当前操作的事务ID，t_ctid改为新tuple的t_ctid，同时把旧的t_infomask加上已冻结状态：HEAP_XMIN_FROZEN（HEAP_XMIN_COMMITTED | HEAP_XMIN_INVALID）。新tuple类似insert的结果，不同的是t_infomask多了个HEAP_UPDATED状态，它的含义是这个版本是由update产生的。如下图： {% asset_img 1.png %} 可见性规则 那怎么判断一个tuple当前事务是否可见呢？tuple对于当前事务的可见性受生成它的事务（t_xmin）的状态、更新它的事务（t_xmax）的状态、当前事务的隔离级别和事务快照（Snapshot）共同影响。\n通过SELECT txid_current_snapshot()可以查看当前的事务快照，里面主要包含三个字段：xmin、xmax、xip\nxmin：当前未完结（提交或回滚）并活跃的事务中最小的XID xmax：所有已完结事务（提交或回滚）中最大的XID，加1后记录在xmax中（比当前所有已提交的事务id都大） xip：当前所有的未完结并活跃的事务的数组 如上图，当前的事务id为315，获取此时的快照，其中xmin为125，xmax为201（200+1），所以此时的snapshot = 125 : 201 : 140。\n事务ID小于xmin的事务表示已经被完结，其涉及的修改对当前快照可见；事务ID大于或等于xmax的事务表示正在执行，其所做的修改对当前快照不可见。事务ID处在 [xmin, xmax)区间的事务，已经完结的对当前事务可见，否则不可见。具体到其涉及的每个tuple，需要结合活跃事务列表与事务提交日志CLOG，判断其所作的修改对当前快照是否可见：\n生成它的事务已提交，且尚未被其他事务修改或锁定的tuple可见。此时t_xmax = 0，且t_infomask为HEAP_XMIN_COMMITTED | HEAP_XMAX_INVALID\n修改它的事务已中止的tuple可见。此时t_xmax != 0，且t_infomask为HEAP_XMAX_INVALID。\n被其他事务正在修改的已冻结的tuple可见。此时t_xmax != 0，且xmax对应的事务状态为进行中，且t_infomask为HEAP_XMIN_FROZEN（HEAP_XMIN_COMMITTED | HEAP_XMIN_INVALID）。\n由当前事务生成的，且尚未被当前事务修改的tuple可见。此时t_xmin为当前事务，t_xmax=0，t_infomask为HEAP_XMAX_INVALID\n已经被其他事务修改，且该事务已提交的tuple不可见。此时t_xmax != 0，t_xmax不为当前事务id，且t_infomask为HEAP_XMAX_COMMITTED\n生成它的事务已中止的tuple不可见。即t_xmin不为当前事务id，且t_infomask为HEAP_XMIN_INVALID，且没有HEAP_XMIN_COMMITTED。\n被当前事务修改的tuple不可见。此时t_xmax为当前事务。\n以上列出的判断规则其实主要还是为了保证只看到已经完结的事务（避免脏读）。因为没有看源码中的方法，来源都是实际实验中测出来的或者其他文章的总结，不能保证一定全，只是用来帮助理解，更深入的可以查看源码或者《PostgreSQL数据库内核分析》 因为更新的时候，会把原版本的t_ctid指向新的tuple，这样就从旧到新形成了一条版本链（InnoDB类似，不过是从新到旧）。不过需要注意的是，更新操作可能会使表的每个索引也产生新版本的索引记录，即对一条元组的每个版本都有对应版本的索引记录，即对一条元组的每个版本都有对应版本的索引记录。这样带来的问题就是浪费了存储空间，旧版本占用的空间只有在进行VACCUM时才能被回收，增加了数据库的负担。为了减缓更新索引带来的影响，8.3之后开始使用HOT机制。定义符合下面条件的为HOT元组：\n索引属性没有被修改 更新的元组新旧版本在同一个page中，其中新的被称为HOT元组 更新一条HOT元组不需要引入新版本的索引，当通过索引获取元组时首先会找到最旧的元组，然后通过元组的版本链找到HOT元组。这样HOT机制让拥有相同索引键值的不同版本元组共用一个索引记录，减少了索引的不必要更新。\n隔离级别的实现 了解了MVCC原理，那PostgreSQL是怎么实现事务隔离级别呢，在这点上，其实InnoDB也类似，都是根据获取快照的时机不同，实现不同的隔离级别：\n读未提交/读已提交：事务重每个query都会获取最新的快照 重复读：事务中只有开始的第一个query会获取快照，后面的都以这个快照为基础，不再重复获取快照 串行读：使用锁系统来实现（SSI） 总结 对比InnoDB，PG的MVCC实现方法有利有弊。其中最直接的问题就是表膨胀，为了解决这个问题引入了AutoVacuum自动清理辅助进程，将MVCC带来的垃圾数据定期清理。PG的回滚可以立即完成，但是InnoDB需要回退undo log中的数据。另一方面判断可见性PG更复杂，开销更大，pg还需要访问clog来判断事务状态，底层也因为采用了堆存储数据而不是聚集索引来组织数据导致VACUUM回收的时候可能会产生碎片。不过对比Serializable级别的实现，PG貌似更先进些，这部分还了解的不是很清楚，留个坑后面再详解\n参考链接 https://peter.grman.at/postgres-repeatable-read-vs-serializable/ https://www.wanghengbin.com/2018/03/29/postgresql-mvcc-lock/ http://www.cnblogs.com/dhcn/p/7120895.html http://blog.itpub.net/6906/viewspace-2562652/ https://tech.meituan.com/2014/08/20/innodb-lock.html http://mysql.taobao.org/monthly/2017/10/01/ https://blog.csdn.net/collin1211/article/details/6024691 "
            }
    
        ,
            {
                "id": 5,
                "href": "https://schecterdamien.github.io/posts/2019/concurrency-problem/",
                "title": "记一次并发问题的排查",
                "section": "posts",
                "date" : "2019.04.24",
                "body": "起源 事情的起源是这样的，Binding是一张多对多的表，主要有sku_code，settlement_sn，enable这几个字段，但是逻辑上sku_code，settlemen_sn，enable=True的在表中应该是唯一的。因为enable=False可能有多条，所以不能在数据库上加联合唯一的索引，但是代码里面有判断。然后有一天测试发现出现两条记录的sku_code，settlemen_sn相同且enable都为True，然后看代码，创建Binding的代码大致是这样的\ndef create_binding(sku_code, settlement_sn)： if not Binding.objects.filter(sku_code=sku_code, settlement_sn=settlement_sn, enable=True).exist(): raise OperationError(\u0026#39;binding_created\u0026#39;) # 一系列有些耗时的校验 do_some_check() return Binding.objects.create(settlement_sn=settlement_sn, sku_code=sku_code, enable=True) 先判断这样的Binding是否存在，存在的话就直接抛异常，不存在的话再进行其他的校验，最后生成对应的Binding。一般情况下没问题，但是如果并发请求的sku_code和settlement_sn都相同，接到请求的几个worker同时从数据库查询发现目标binding不存在，做出可以创建的判断（因为下面存在一些耗时的校验让这种情况的概率变得很高），然后就创建了sku_code和settlement_sn都相同的记录。 因为是公司内部使用的财务规则系统，也就几个人在用，所以做的时候没怎么考虑并发问题。最后发现其实是前端没有做按钮的防重点，用户连续在按钮上点了两下，造成了这个问题。 我们用的是pg（等下会说为什么强调是pg），这里其实是发生了幻读。那改事务隔离级别可以解决吗，可重复读和串行化不是能解决幻读吗。。。。。肯定不行，一言不合就改数据库事务隔离级别肯定是不行的，而且改了也没法解决这种幻读问题(后来才知道其实串行化可以，但需要加上失败重试的逻辑)。那加锁吧！当时也没多想，迷迷糊糊的在判断上加个锁：\ndef create_binding(sku_code, settlement_sn)： if not Binding.objects.filter(sku_code=sku_code, settlement_sn=settlement_sn, enable=True).select_for_update).exist(): raise OperationError(\u0026#39;binding_created\u0026#39;) ..... 查询上加上select_for_update()，阻塞住并发的读，完美！发到测试环境，一看，并不行\u0026hellip;还是会生成重，再回头看才明白这个锁有问题。首先，django的select_for_update加上exist()其实是不会生成\u0026rsquo;select \u0026hellip; for update\u0026rsquo;语句的，然后就算生成了，但是因为没有这样的数据，所以没有row可以被锁，这个锁其实没有任何作用。\n解决 那怎么解决呢，分布式锁肯定是可以的，给判断的代码块加上锁，这样创建binding的请求就变成串行的了，如果对并发没要求，比如我们这种场景为了防止重点，可以使用这种办法。代码块就变成这样了：\ndef create_binding(sku_code, settlement_sn)： # 获取分布式锁 get_lock() if not Binding.objects.filter(sku_code=sku_code, settlement_sn=settlement_sn, enable=True).exist(): raise OperationError(\u0026#39;binding_created\u0026#39;) # 一系列有些耗时的校验 do_some_check() result = Binding.objects.create(settlement_sn=settlement_sn, sku_code=sku_code, enable=True) # 释放分布式锁 release_lock() return result 除此之外有没有别的办法呢，其实我们就是想锁住一个“不存在”的一行，google了一下，搜到一篇文章：https://rosscoded.com/blog/2018/05/02/locking-phantom-postgresql/，这里面在pg的数据库级别给出了解决办法。首先可以使用ON CONFLICT语句，其次还可以使用advisory locks，劝告锁，这是pg独有的一种锁，思路挺有意思，不过这是库级别的锁，用多了也不好。但是这些都得在代码里面写sql，最后我们还是选择了基于redis的简单的分布式锁来解决。\n回到之前说的，为啥强调是pg呢，因为后来试了一下，在mysql里面，其实是可以给不存在的数据加锁的，mysql里面这个叫gap lock，间隙锁，专门用来解决幻读问题。比如直接select * from binding where sku_code = \u0026quot;123\u0026quot; for update其实会同时加record Lock和gap lock，把已经存在的sku_code=123的行给锁住，同时还会锁住不存在的这些目标行，就是这时其他事务其实是没法写sku_code=123的数据的。mysql只有在可重复读以上的隔离级别才会自动加gap lock。\n之后有空再详细写写上面的几种锁。\n参考链接 https://rosscoded.com/blog/2018/05/02/locking-phantom-postgresql/ https://ningyu1.github.io/site/post/50-mysql-gap-lock/ "
            }
    
        ,
            {
                "id": 6,
                "href": "https://schecterdamien.github.io/posts/2019/cuckoo-filter/",
                "title": "Cuckoo Filter",
                "section": "posts",
                "date" : "2019.04.17",
                "body": "比Bloom-filter更好的过滤器 我们经常会遇到一个需求，就是判断一个元素是否在某个集合里面，首先想到的是维护一个HashMap（比如python中的字典），但是存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，那 HashMap 占据的内存大小就变得很可观了，还需要存储对象的key（防止碰撞后没法确定元素），内存可能会装不下，我们需要一个空间效率更高的数据结构，这个时候我们一般会想到Bloom-filter。Bloom-filter可以看作k个hash函数+Bitmap，原理是通过k个hash函数将元素映射到Bitmap的k个位置，因为Bitmap只用1个bit就可以存储一个值，所以空间效率非常高，关于Bloom-filter，网络上已经有很多介绍的文章，就不赘述了。对于判断一个数据是否在某个海量数据的集合里面，Bloom-filter有奇效，比如应对缓存穿透、垃圾邮件的判断等\n但是Bloom-filter并不是完美的，比如Bloom-filter不支持删除，一旦需要删除一个元素，就只能重建Bloom-filter，简单的把元素hash后的k个位置置0会造成其他元素的误判（误判一个已经存在的元素为不存在，破坏了Bloom-filter的特性），对于此，有不少的Bloom-filter的变种，比如counting Bloom，d-left counting Bloom，大致的原理是把Bitmap位数组的每一位扩展为一个小的计数器。增加了实现复杂度的同时还降低了空间利用率，那有没有更好的替代方案呢？所以由此引入这次的主角：Cuckoo-Filter\nCuckoo Hash 介绍Cuckoo-Filter之前得先说说Cuckoo Hash。Cuckoo Hash其实是一种解决hash冲突的策略。\nCuckoo是布谷鸟的意思，也就是我们常说的杜鹃。“鸠占鹊巢”里面的“鸠”的就是类似杜鹃这种鸟类。这种鸟有一种即狡猾又贪婪的习性，它不肯自己筑巢，而是把蛋下到别的鸟巢里，而且它的幼鸟又会比别的鸟早出生，布谷幼鸟天生有一种残忍的动作，幼鸟会拼命把未出生的其它鸟蛋挤出窝巢，今后以便独享“养父母”的食物。借助生物学上这一典故，cuckoo hashing处理碰撞的方法，就是把原来占用位置的这个元素踢走，不过被踢出去的元素还要比鸟蛋幸运，因为它还有一个备用位置可以安置，如果备用位置上还有人，再把它踢走，如此往复。直到被踢的次数达到一个上限，才确认哈希表已满，并执行rehash操作，下图是一个Cuckoo Hash的例子：\nCuckoo hash会有多个hash函数（一般是两个），把一个元素x映射到多个位置上，这一点和Bloom-filter很像，但是Cuckoo hash只会在多个位置中选择一个空的位置来存储x（或其他信息，取决于实现）。如果都满了，就随机选一个位置“踢走”那个元素，把那个元素踢到它自己的替代位置上去，如果它的替代位置也满了，则继续踢。图中就是要插入一个x，发现hash后的两个位置都被占了，所以随机选择了6的位置踢走了元素a，a找到了自己的备用位置4发现已经被c占了，接着把c踢走，c最后找到了一个空的位置1，整个插入过程完成。 这样会造成一个问题，就是插入的开销会在元素越来越多的时候变得越来越大，元素可能会一直踢来踢去，甚至出现死循环，比如下图（极端情况）\n元素x经过2个hash后的位置都被占了，随机选择一个位置12，把e踢走，e的备用位置被a占了，踢走a，a又踢走了b，b又踢走了c，c踢走了d，d的备用位置是12，于是又把刚插入的x给踢走了……陷入了死循环，所以需要一个上限，达到上限只能重建。此时可以衡量Cuckoo Hash的最大负载因子，负载因子 = 已经存入的元素 / 总的bucket。上图中这种可以看作只有一个slot的bucket，增加slot比如图c，可以大大减少冲突后踢走元素的概率，每个bucket对应一个hash值，相同hash值的元素都存在同一个bucket的不同slot中，除非2个bucket的8个slot都满了，否则不会踢元素。一维数组实现的cuckoo hash的负载因子大小和其他hash策略没什么区别，只有50%，但是多路slot的实现，比如图c中，能达到90%以上，可以说效率很高了。\nCuckoo-Filter设计 本文主要参考了酷壳和CMU论文的实现，这篇论文首先提出了Cuckoo-Filter，很有参考价值。 论文中在Cuckoo-Filter的设计上比起基本的Cuckoo Hash有不少的优化。作为过滤器，空间肯定是能省就省，所以在每个slot中不会存原本的元素x，而是存的元素x的fingerprint(指纹，记做f)。由于存的是指纹，没有存x本身或者x的备用位置，或者那么在寻找元素的备用位置的时候怎么知道备用位置呢。作者采用了一种比较巧妙的办法，第一个地址用hash(x)来确定，第二个地址用hash(f)和第一个地址做异或来确定，这样不管当前是哪个地址，直接用当前地址和hash(f)做异或就可以得到另外一个地址。同时，插入的时候优先选择空的位置，而不是踢走其他的元素。\n刚开始其实还有一个比较疑惑的点，为什么求第二个地址的时候用的是hash(f)来异或呢，而不是直接异或f得到第二个地址，最后在论文中找到了答案(有些词不好翻译就直接贴原文了)：\nIn addition, the fingerprint is hashed before it is xor-ed with the index of its current bucket to help distribute the items uniformly in the table. If the alternate location were calculated by “i ⊕ fingerprint” without hashing the fingerprint, the items kicked out from nearby buckets would land close to each other in the table, if the size of the fingerprint is small compared to the table size. For example, using 8-bit fingerprints the items kicked out from bucket i will be placed to buckets that are at most 256 buckets away from bucket i, because the xor operation would alter the eight low order bits of the bucket index while the higher order bits would not change. Hashing the fingerprints ensures that these items can be relocated to buckets in an entirely different part of the hash table, hence reducing hash collisions and improving the table utilization.\n主要是因为fingerprint可能远小于hash(x)，直接异或fingerprint可能导致异或的只有地址1的低位，造成的结果是地址2可能就在地址1的附近，8位的fingerprint下地址1和地址2最大偏移距离只有256，两个地址产生了某种关联性，会加大产生冲突的可能（直接理解是没问题的，但是作者没有给出证明） 除了上面说的这些，作者还做了一个优化来节约空间，称之为\u0026quot;Semi-sorting Buckets\u0026quot;。这种做法的前提是fingerprint在slot中的顺序不影响查询。具体的比如4个slot的bucket，每个slot中保存4位的fingerprint，那么bucket一共是16位。如果我们对4位的fingerprint进行排序，总共有3876种可能（??这个地方没怎么看懂，不知道这个数怎么出来的，留个坑），也就是16位的空间没有完全利用起来，3876\u0026lt;2^12，所以我们可以建立一个12位数值到这部分16位的值的映射。bucket只保存这个映射的key，也就是12位，每次对bucket的处理都相当于经过了一次解码编码的过程，时间上会造成一定的损耗，但是空间利用率更高了，16个bit的bucket节约了4个bit的空间，相当于3/4。 下面会贴出插入、查找、删除的伪代码(来源论文，没有做Semi-sorting的bucket)：\n插入 f = fingerprint(x) i1 = hash(x) i2 = i1 xor hash(f) if bucket[i1] or bucket[i2] has an empty entry then add f to that bucket return Done i = randomly pick i1 or i2 for n=0;n\u0026lt;MaxNumKicks;++n randomly select an entry e from bucket[i] swap f and the fingerprint stored in entry e i = i xor hash(f) if bucket[i] has an empty entry then add f to bucket[i] return Done return Failure 首先计算了元素x的指纹f、两个地址i1和i2，然后查看i1和i2是否有空位，有的话直接插入，返回成功。没有的话随机挑一个踢出去，取踢出去的值赋给f，通过hash(f) xor i找到这个踢出去的元素的备用地址，再看是否被占用，没有的话直接插入，有的话重复上面一个过程，超过最大踢的次数就表明过滤器已经满了需要重建。\n查找 f = fingerprint(x) i1 = hash(x) i2 = i1 xor hash(f) if bucket[i1] or bucket[i2] has f then return True return False 查找的比较简单，计算出了两个地址，如果在两个slot中发现了指纹说明元素存在（有一定误判率，下面会分析）\n删除 f = fingerprint(x) i1 = hash(x) i2 = i1 xor hash(f) if bucket[i1] or bucket[i2] has f then remove a copy of f from this bucket return False 和查找一样，删除也有一定的误判率，如果在被删除元素的备选位置上，有个元素的备选位置是被删除元素的当前位置，并且它的指纹也和被删除元素一样，那么即使删除了当前元素，再找的时候也会产生误判这个元素还存在。\nCuckoo-Filter相关分析 Cuckoo-Filter和Bloom-Filter一样，存在着一定的误判率，比如两个元素x、y，如果x、y的fingerprint一样都为f，而且同时hash(x) == hash(y) 或者 hash(x) == hash(y) ^ f 则过滤器根本无法分辨x和y，插入x，再查y发现y也存在，其实查到的是x。这种碰撞发生的概率叫做false positive(假阳率)，就是有可能判断一个并不存在的元素为存在，类似Bloom-Filter。另一方面，对于不存在的元素，肯定能返回不存在的结果。 对Cuckoo-Filter来说，可以从这几个方面来衡量它的好坏，一个是空间利用率，一个是插入、查找、和删除的时间开销。\n在计算空间利用率之前，可以先设置相关的变量。这里我们沿用作者的设定：\nε表示我们期望达到的过滤器的错误率，f表示指纹的长度（bit），α表示负载因子（load factor），b表示每个bucket的slot的数量，m表示过滤器中一共有多少个bucket，n表示我们要插入的item的总数，C表示的平均每个item占用的bit数。我们要计算的就是C，代表的其实就是Cuckoo-filter的空间效率。\n那么这个值怎么算呢，平均每个item的大小(bit)=过滤器的总的大小(bit)/插入的item的数目，最后化简得到f/α。也就是说明和指纹长度成正比，和负载因子成反比。说明负载因子越大，空间效率越高，这个好理解。同时指纹长度越小，空间效率越高，那指纹长度能不能无限小呢？当然不行，比如求出了一个地址hash(x)，那备用的地址就只有f ^ 2种可能，指纹长度越小，碰撞的概率就越大，间接的影响了负载因子的大小，作者在论文中表明了这种影响。 除此之外，还有一个约束条件，就是我们期望的错误率ε。错误率我们怎么和指纹长度联系起来呢？错误率其实就是把一个没在过滤器中的元素给误判成在存在的概率\n上图是计算错误率的公式，比如插入x，hash(x)得到第一个bucket的位置，这个bucket和备用bucket一共有2b个元素。和其中某个元素指纹相同的概率为1/2^f，先计算出和2b个元素指纹不碰撞的概率，然后用1减去不碰撞的概率得到就是错误率。\n代入期望达到的错误率ε，得到指纹长度的下界。这里表明了一个问题，越大的cuckoo-filter为了保持一定的错误率，需要越大的指纹长度，否则错误率将增加。\n和上面计算空间效率的公式结合，可以得到这个公式，指明了我们期望的错误率越小或每个bucket的slot数目越大则平均每个item的空间损耗的上界越大。\n查找的时间消耗。查找一个元素，最多会查找2b次，删除也是，可以认定为O(1)的时间复杂度。插入元素的时间复杂渐进为O(1)，在前期bucket没满的时候，直接插入即可，满了就开始踢元素，当负载因子增加的时候，插入的时间将来越久，最终超过最大的踢的次数就只能重建了，时间复杂度的具体证明见原论文。\nCuckoo-Filter和Bloom-Filter对比 Cuckoo-Filter对比Bloom-Filter，最主要的就是支持删除，虽然counting Bloom也支持删除，但是空间利用率又远远不如Cuckoo-Filter。在空间利用率上，原论文给出了对比：\n上面我们讨论过，Cuckoo-Filter的空间效率和我们预定的错误率是有关系的，Bloom-Filter也是这样的，从图中可以看到，当错误率小于3%的时候，semisort-Cuckoo Filter的空间效率是比Bloom-Filter要高的，即使是不是semisort优化的普通Cuckoo，在图中可见的0.1%错误率以内，也是要比Bloom-Filter空间效率要高。而在实际使用中，我们一般不会容忍这么高的错误错误率，所以实际上来说Cuckoo-Filter的空间性能要更好一点。 时间性能上，两者的查找都是常量时间复杂度，但是如果数据集过于巨大以至采取了持久化的策略，则Cuckoo-Filter要优于Bloom-Filter，因为最多只需要读取两个bucket，而Bloom-Filter则需要读K次。对于插入，Cuckoo-Filter在负载因子较大的时候因为会踢数据，所以可能会比Bloom-Filter更慢，甚至出现插入失败的情况，这种时候就只能重建了。而Bloom-Filter的插入不会受到负载因子的影响，另外，它还有跟Bloom-Filter共有的一个缺点，就是访问空间地址不连续，通常可以认为是随机的，这样严重破坏了程序局部性，对于Cache流水线来说非常不利。\n关于两者对比的更多的讨论可以查看这个问题：https://stackoverflow.com/questions/867099/bloom-filter-or-cuckoo-hashing\n综上，Cuckoo-Filter是一种很优秀的数据结构，但是目前相关的工程化的应用还不是特别多，不过这也给了我们机会去实现一个更高效的轮子。\n参考链接 https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf https://coolshell.cn/articles/17225.html https://brilliant.org/wiki/cuckoo-filter/ https://stackoverflow.com/questions/867099/bloom-filter-or-cuckoo-hashing http://legendtkl.com/2017/07/23/about-hash-table/ https://www.cnblogs.com/chuxiuhong/p/8215719.html "
            }
    
        ,
            {
                "id": 7,
                "href": "https://schecterdamien.github.io/posts/2019/python-debug/",
                "title": "怎么高效的调试python程序(1)",
                "section": "posts",
                "date" : "2019.02.24",
                "body": " 这篇文章是受到18年pycon上张翔大神演讲的启发，当时他的演讲的题目是《我的python进程怎么了》，主要是介绍了python进程调试的一些工具和方法，总结的比较全，当时在现场听完感觉受益匪浅，但是一直没去整理，这篇文章大致也是按照他的ppt的大纲来写的。\n我们代码写完后，运行时经常会遇到这样那样的问题，有一些很容易就能发现，因为代码跑到这里就直接就报错了，抛异常了，一般看日志的报错信息就能发现具体是哪里出了问题。但是还有一部分是没法从日志中看出来的：“为什么我的python进程卡住了”，“为什么我的python进程消耗这么多的内存”，“为什么我的python进程消耗了这么多的cpu”，卡住了是因为死锁了还是阻塞在io上了？消耗内存多了是因为存在内存泄漏还是数据结构设计的不合理？这种时候就需要一系列的工具来排查，工欲善其事，必先利其器。\nprint\u0026amp;log 相信对大部分人来说，print和log是最常用的调试方法了。在感觉有问题的地方，加上print和log来输出一些状态信息和变量，每个python程序员都是这方面的大师。\nprint\u0026amp;log大法简单粗暴，但往往很有效。缺点是需要提前了解你的代码，知道在哪里print\u0026amp;log，而且需要修改后重启你的进程，调试完还要删除调试的代码。\npdb pdb是python自带的一个库，为python程序提供了一种交互的源代码调试功能，主要特性包括设置断点、单步调试、进入函数调试、查看当前代码、查看栈片段、动态改变变量的值等。pdb可以认为是python下的gdb，两者保持了一样的用法。\n有两种不同的方法使用pdb，一种是直接在命令行指定参数启动pdb，比如直接python -m pdb pdb_test.py 可以进入命令行调试模式，接下来可以输入相应的调试命令进行调试，比如：l是查看当前代码，b是设置断点，n是执行下一行，单步调试。输入h可以查看各命令的使用说明。\npdb单步执行太麻烦了，第二种方法是直接在代码中import pdb，直接在代码里需要调试的地方放一个 pdb.set_trace() 设置一个断点，程序运行到这里会暂停并进入pdb调试环境，可以用pdb 变量名查看变量，或者c继续运行。关于pdb更详细的使用方法，可以查看官方文档\n但是实际工作中，很多时候我们都是使用flask或者django等框架来开发，特别是django，很多时候需要在django shell里面进行一系列的调试，这个时候pdb就不好启动了，可以使用django-pdb。\n除了pdb，还有一个第三方的开源的python调试器Ipdb，具有语法高亮、tab补全，更友好的输出信息等高级功能，ipdb之于pdb，就相当于IPython之于Python，虽然都是实现相同的功能，但是，在易用性方面做了很多的改进。如果使用ide，比如PyCharm，很多都自带了断点设置，变量查看的功能，使用上更加方便友好。\nsys sys模块包括了一组非常实用的服务，内含很多函数方法和变量，用来处理Python运行时的配置以及资源，从而可以与当前程序之外的系统环境交互，是python程序用来请求解释器行为的接口。\n很长一段时间里面，都不清楚sys模块的重要性，说这是python标准库中最重要的模块之一也不为过了，后来陆续接触到sys模块的一些黑科技般的方法，才逐渐的了解到它的强大，里面很多的方法涉及到的背景和知识都能另起一篇文章了，所以这里只介绍一部分。\nsys._getframe([depth]): 返回一个栈帧对象，depth为栈顶部向下的深度，默认为0，返回的是当前的栈帧。\n\u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; frame = sys._getframe() \u0026gt;\u0026gt;\u0026gt; dir(frame) [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, \u0026#39;__getattribute__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;, \u0026#39;clear\u0026#39;, \u0026#39;f_back\u0026#39;, \u0026#39;f_builtins\u0026#39;, \u0026#39;f_code\u0026#39;, \u0026#39;f_globals\u0026#39;, \u0026#39;f_lasti\u0026#39;, \u0026#39;f_lineno\u0026#39;, \u0026#39;f_locals\u0026#39;, \u0026#39;f_trace\u0026#39;] \u0026gt;\u0026gt;\u0026gt; assert frame.f_back == None \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; dir(frame.f_code) [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, \u0026#39;__getattribute__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;, \u0026#39;co_argcount\u0026#39;, \u0026#39;co_cellvars\u0026#39;, \u0026#39;co_code\u0026#39;, \u0026#39;co_consts\u0026#39;, \u0026#39;co_filename\u0026#39;, \u0026#39;co_firstlineno\u0026#39;, \u0026#39;co_flags\u0026#39;, \u0026#39;co_freevars\u0026#39;, \u0026#39;co_kwonlyargcount\u0026#39;, \u0026#39;co_lnotab\u0026#39;, \u0026#39;co_name\u0026#39;, \u0026#39;co_names\u0026#39;, \u0026#39;co_nlocals\u0026#39;, \u0026#39;co_stacksize\u0026#39;, \u0026#39;co_varnames\u0026#39;] \u0026gt;\u0026gt;\u0026gt; frame.f_code.co_name \u0026#39;\u0026lt;module\u0026gt;\u0026#39; frame.f_back返回上一个栈帧对象，也就是调用栈的上一层，这里因为是直接在python shell中使用的，调用栈就一层，所以frame.f_back返回None。其他的，比如f_locals返回当前栈帧的本地变量，f_globals返回全局变量。通过f_code可以获得PyCodeObject。这个对象保存了栈帧引用的代码块的一些信息，比如函数名称co_name，这里因为已经是栈底了，所以frame.f_code.co_name显示的是\u0026lt;module\u0026gt;。所以可以通过这些方法写一个函数，可以获取这个函数调用者的一些信息：\ndef func(): frame = sys._getframe(1) code = frame.f_code caller_msg = f\u0026#39;func called by {code.co_name} in file: {code.co_filename} {frame.f_lineno} line\u0026#39; print(caller_msg) sys._current_frames(): 返回函数调用时，每个线程标识符与顶层堆栈帧的字典映射，这里只有一个线程，所以字典只有一项：\n\u0026gt;\u0026gt;\u0026gt; sys._current_frames() {140736139600768: \u0026lt;frame object at 0x106484528\u0026gt;} sys.getswitchinterval()：返回解释器的“线程切换间隔”，也就是多线程下一个线程执行多久会被gil切换。\nsys.getrecursionlimit(): 获取最大递归的层数\nsys.getrefcount(object)：返回对象的引用计数，执行的时候已经又被引用了一次，所以真实的引用次数应该-1\nsys.getallocatedblocks()：返回解释器当前分配的内存块数量。主要用于追踪和调试内存泄漏。受解释器内部缓存影响，每次调用返回的值都可能不一样，可以通过调用_clear_type_cache()和gc.collect()方法获取更可预测的结果。\n这里重点介绍了sys._getframe方法，因为之前就做过一个这样的需求，要在一个log工具类中打印出调用这个类的调用者的信息，所以印象很深刻。但是官方文档不建议通过这种方式获取当前栈帧，官方文档并不保证在Python的所有实现中都存在这个方法，建议使用inspect.currentframe()获取当前栈帧。\n除了上面这些，sys里面还有很多强大的工具，更详细的可以看看官方文档\nprofile 如果我们的进程有大量的计算，又没有对应的输出信息，可能会让我们误以为卡住了，又或者我们需要对性能进行调优，我们需要一些工具来进行性能分析。python官方库有两个很方便的工具：Profile和cProfile（还有个hotshot，但是已经不维护了，所以忽略）。\n这两者的使用方法完全一样，不同的是cProfile是c实现的，运行开销比较小，适合分析运行时间比较长的项目，是我们大部分情况下的首选。Profile是一个纯python的模块，运行开销比较大，如果想扩展其他的功能的话，可以继承这个模块。\n提到cProfile，就不得不提pstats，这个模块是用来处理cProfile的分析结果。有两种方法使用cProfile，一种是在命令行里使用python3 -m cProfile profile_test.py，可以得到整个profile_test.py程序运行的分析结果，或者直接在程序内使用，举个栗子:\nfrom cProfile import Profile import pstats def foo1(): return foo2() * 3 def foo2(): return foo3() * 2 def foo3(): # \u0026#34;this call tree seems ugly, but it always happen\u0026#34; return 1 def flat_foo(): return 1 * 2 * 3 def flat_foo2(): a = 1 b = 2 c = 3 return a * b * c def calculate1(): sum = [] for i in range(10000): sum += [i * i * i] def calculate2(): sum = [] for i in range(10000): sum = sum + [i * i * i] def main(): for i in range(100000): if i % 10000 == 0: calculate1() elif i % 10000 == 1: calculate2() elif i % 3 == 1: flat_foo() elif i % 3 == 2: flat_foo2() else: foo1() if __name__ == \u0026#39;__main__\u0026#39;: prof = Profile() prof.runcall(main) ps = pstats.Stats(prof) ps.strip_dirs().sort_stats(\u0026#34;tottime\u0026#34;).print_stats() 脚本引入Profile类，分析main的执行情况，收集到性能分析的数据后，通过pstats的Stats来进行排序并输出到终端：\n对于上面的的输出，每一个字段意义如下：\nncalls 函数总的调用次数 tottime 函数内部（不包括子函数）的占用时间 percall（第一个） tottime/ncalls cumtime 函数包括子函数所占用的时间 percall（第二个）cumtime/ncalls. filename:lineno(function) 文件：行号（函数） 分析下这个结果，我们会发现一些有意思的事情。执行时间最长的是calculate1，对比下calculate2发现两者的差异只是一个使用+=操作，一个是直接+的操作，因为列表是可变对象，python对可变对象的+=操作是直接在这个可变对象原分配的内存块上进行，而每次+操作的结果都会重新分配一块内存，无形中降低了效率，这部分性能损耗还是挺大的，可以看到速度相差了100多倍。接下里是foo1，foo1其实只是做了一个1*2*3的操作，但是确需要调用3层的函数来计算，flat_foo和flat_foo2只有1层，说明了调用栈频繁的生成和销毁其实是有一定的运行开销的。那为什么flat_foo和flat_foo2的运行时间也不一样呢，因为python解释器会进行一系列优化，比如对于1 * 2 * 3这种表达式会进行常量替换，直接替换成6，这样就不用每次都计算了，但是对于a * b * c解释器就没法进行替换了，因为python是动态语言，没法进行静态分析，abc的值只有在运行时才能确定。 除了直接在终端展示，我们还可以保存cProfile分析的结果。可以在运行时指定，比如python3 -m cProfile profile_test.py -o result，或者在程序里面prof.dump_stats('result')。保存下来的结果可以用一些图形化的工具进行分析，比如visualpytune、qcachegrind、runsnakerun等。\n其他 本来打算一口气把演讲中提到的所有调试工具和方法都写完的，但是真正写的时候发现每个工具都能牵扯出很多的东西。而自己水平也有限，不敢随便就下笔写，只能查阅确认后再写，所以很耗费精力，最后还是打算分成几个部分来写了，加油吧\n参考链接 https://www.ibm.com/developerworks/cn/linux/l-cn-pythondebugger/index.html https://zhuanlan.zhihu.com/p/25942045\nhttps://docs.python.org/3/library/inspect.html\nhttps://docs.python.org/3.6/library/sys.html http://www.cnblogs.com/xybaby/p/6510941.html\nhttps://zhuanlan.zhihu.com/p/24495603\n"
            }
    
        ,
            {
                "id": 8,
                "href": "https://schecterdamien.github.io/posts/2019/unicode/",
                "title": "unicode到底是个什么鬼",
                "section": "posts",
                "date" : "2019.01.24",
                "body": " 编码问题可以说是python中非常让人头疼的一个问题了，看到知乎上一个哥们说：一旦你走上了编程之路，如果你不把编码问题搞清楚，那么它就像幽灵一般纠缠你整个职业生涯，各种灵异事件会接踵而来。只有充分发挥程序员死磕到底的精神你才有可能彻底摆脱编码问题带来的烦恼。 实在不能更同意了。前几天看到一篇文章写的挺不错https://zhuanlan.zhihu.com/p/40834093。网上也有很多类似的文章，一般都会说到python3的str的编码是unicode。同时在另一本知名的书上《effective python》有这样一段：\n把Unicode字符表示为二进制数据（也就是原始8位值）有许多的办法。最常见的编码方式就是UTF-8。但是大家要记住，python3的str实例和python2的unicode实例都没有和特定的二进制编码形式相关联。要把Unicode字符转换成二进制数据，就必须使用encode方法。想要把二进制数据转换成Unicode字符，则必须使用decode方法。\n看到这里我就很分裂了，那python3的str到底是什么编码格式呢？如果没有和特定的二进制编码形式相关联，那str在内存中怎么表示呢？unicode到底是个什么鬼？\nUnicode 说到这里，就得去研究下unicode。\n刚开始没有的unicode的时候，英语国家使用ascii，中国使用gbk，日本使用shift_jis……大家都使用自己的编码协议，大家交流起来就特别麻烦，一不小心就乱码了。假设没有一门可以包容所有语言的编码，同时有n个适用于各国自己语言的编码，那大家需要交流的话就要n*(n-1)种映射协议来转换编码，让大家都能交流，这无疑对互联网来说是场灾难。所以unicode出现了，它对世界上大部分的文字系统进行了整理、编码，使得计算机可以用更为简单的方式来呈现和处理文字。\n大概来说，Unicode编码系统可分为编码方式和实现方式两个层次。重点来了，Unicode的编码方式和实现方式是不同的，编码方式是指的字符集，也就是指定了每个值和字符的映射关系，比如我可以自己制定一个很简单的字符集类似于:{1: '你', 2: '好'，……，260: '呢'}，这里指定的是值和字母的映射关系，1代表的就是\u0026rsquo;你\u0026rsquo;，2代表的是\u0026rsquo;好\u0026rsquo;，260代表的是\u0026rsquo;呢\u0026rsquo;。根据编码方式我们可以有不同的实现方式。比如如果是用定长编码来实现，要存储260这个中文字符，我们至少需要两个字节，所以我们可以写死用两个字节来存储，尽管对于前面256个字符来说，第一个字节都是0。如果使用变长编码来实现，可以把前面128个汉字用一个字节表示，留出首位当作标识位，其他的汉字用两个字节表示。还有比如两个字节是大端序还是小端序会影响到第一个字节是高位还是第二个字节是高位等等，这些都是不同的实现方式。\n所以Unicode我们通常说的是指的其编码方式，就是映射关系。Unicode的实现方式称为Unicode转换格式（Unicode Transformation Format，简称为UTF）。我们用的比较多的有UTF-8，UTF-16，UTF-32等。所以我们说python3中的str的编码方式是unicode这个说法就有问题了，unicode只是一个字符集，没有约定实现，具体的实现还要看是采用UTF-8还是UTF-16还是别的方式，那到底python中采取的是unicode的哪种实现方式呢？\n真相大白 然而这个问题，在中文网络上几乎没找到相关的答案，看了好多的博客，都只是说python3的str编码是unicode，这句话本身就有问题。最后还是在stackoverflow上找到了答案: What is internal representation of string in Python 3.x 以及 How is unicode represented internally in Python?。\n总结一下，就是python在3.3之前，包括python2，具体的内部unicode采用哪种方式实现其实是编译时的选项。取决于系统的本机字节顺序以及是否选择了UCS2或UCS4。UCS4的话就是采用UTF-32来实现，UCS2的话就采用UTF-16来实现，本机字节顺序决定了是UTF-16 BE还是UTF-16 LE。也就是一旦在编译的时候设置好了，之后python里面unicode的实现都是这种方式。python3.3之后，采用了一种更为灵活的方式来表示，字符串可能是ascii, latin-1, utf-8, utf-16, utf-32等编码形式中的一种，就是说不再是写死一种方式了（这个地方还没完全弄明白，先留个坑），这个主要是pep 393中约定的：PEP 393 \u0026ndash; Flexible String Representation\n参考链接 https://www.cnblogs.com/malecrab/p/5300503.html https://zh.wikipedia.org/wiki/Unicode https://zh.wikipedia.org/wiki/通用字符集#Unicode和ISO_10646的关系 "
            }
    
        ,
            {
                "id": 9,
                "href": "https://schecterdamien.github.io/posts/2018/namedtuple/",
                "title": "namedtuple第一个参数有什么用？",
                "section": "posts",
                "date" : "2018.12.19",
                "body": " namedtuple是python中一个简单实用的数据结构，但是很不爽的是每次使用的时候都需要给第一个参数指定一个字符串，而这个字符串在实际使用中似乎并没有什么作用。比如\n\u0026gt;\u0026gt;\u0026gt; from collections import namedtuple \u0026gt;\u0026gt;\u0026gt; Student = namedtuple(\u0026#39;StudentTuple\u0026#39;, [\u0026#39;sex\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; s = Student(\u0026#39;male\u0026#39;, \u0026#39;callmedad\u0026#39;, 22) \u0026gt;\u0026gt;\u0026gt; s.age 22 我操作的对象都是Student，而不是StudentTuple，那我为什么还要传一个\u0026rsquo;StudentTuple\u0026rsquo;，这个字符串似乎对我没有任何帮助。stackoverflow同样有人提了这个问题：传送门1，传送门2. 看了下回答，然后又看了下namedtuple的源码，总算明白了。 接着上面的代码，我们可以看下Student是个啥。\n\u0026gt;\u0026gt;\u0026gt; import inspect \u0026gt;\u0026gt;\u0026gt; inspect.isclass(Student) True \u0026gt;\u0026gt;\u0026gt; Student \u0026lt;class \u0026#39;__main__.StudentTuple\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; Student \u0026lt;class \u0026#39;__main__.StudentTuple\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; s.__class__ \u0026lt;class \u0026#39;__main__.StudentTuple\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(namedtuple) \u0026lt;class \u0026#39;function\u0026#39;\u0026gt; 我们大致知道这几点：1. Student是个类，并且只是一个类的引用，查看s.__class__知道，这个类定义的名字是StudentTuple，就是我们传的第一个参数。2. namedtuple是个方法，但是返回的是一个新的类，也就是说这是一个类的工厂方法。\n既然是一个生成类的工厂方法，那么肯定就需要知道类的名字，所以这就是第一个参数的意义。然后，这一切是怎么实现的呢？\n看下namedtuple的源码，其实非常简单粗暴\ndef namedtuple(typename, field_names, *, verbose=False, rename=False, module=None): ... class_definition = _class_template.format( typename = typename, # 第一个参数 field_names = tuple(field_names), # 各种检验后的属性列表 num_fields = len(field_names), arg_list = repr(tuple(field_names)).replace(\u0026#34;\u0026#39;\u0026#34;, \u0026#34;\u0026#34;)[1:-1], repr_fmt = \u0026#39;, \u0026#39;.join(_repr_template.format(name=name) for name in field_names), field_defs = \u0026#39;\\n\u0026#39;.join(_field_template.format(index=index, name=name) for index, name in enumerate(field_names)) ) namespace = dict(__name__=\u0026#39;namedtuple_%s\u0026#39; % typename) exec(class_definition, namespace) result = namespace[typename] result._source = class_definition ... 核心代码就这几行，主要思路就是填充一个字符串的类的模版，然后动态执行生成一个类。 _class_template大致长这个样(简化后)：\n_class_template = \u0026#34;\u0026#34;\u0026#34;\\ from builtins import property as _property, tuple as _tuple from operator import itemgetter as _itemgetter from collections import OrderedDict class {typename}(tuple): \u0026#39;{typename}({arg_list})\u0026#39; __slots__ = () _fields = {field_names!r} def __new__(_cls, {arg_list}): \u0026#39;Create new instance of {typename}({arg_list})\u0026#39; return _tuple.__new__(_cls, ({arg_list})) def __repr__(self): \u0026#39;Return a nicely formatted representation string\u0026#39; return self.__class__.__name__ + \u0026#39;({repr_fmt})\u0026#39; % self .... {field_defs} \u0026#34;\u0026#34;\u0026#34; 有人说这种方式很\u0026quot;dirty\u0026quot;，因为是用eval来动态执行的，但是这种方法确实是很简单高效，除了这种方式，其实也可以通过type和元类来动态生成一个类，有空再补上\n"
            }
    
        ,
            {
                "id": 10,
                "href": "https://schecterdamien.github.io/posts/2018/about-absurd/",
                "title": "关于语言的杂想",
                "section": "posts",
                "date" : "2018.11.19",
                "body": " 最近在看西西弗神话，有一些感想。\n首先，其实没看多少，但是真的是看的很费劲，很头疼。因为，实在是看不明白，这个看不明白我感觉或许不是因为我理解不了，或许是更深层次的无力感。加缪所描述的荒谬感我觉得我应该再能感同身受不过了，我也是通过一些其他途径发现荒谬感这一说法，然后顺着源头找到了加缪。但是结果很沮丧，因为翻译的实在太生硬了，主谓宾都不全，单从词的翻译看来或许还好，但是一旦汇成一个句子，看起来还真的很“荒谬”。或许对于小说来说，翻译错一点不要紧，某种程度上来说小说的“容错率“比较高，因为信息密度不高，但是对一部讲哲学的散文来说，差之毫厘，谬以千里。\n从另一个角度来看，翻译确实是很难，不同语言之间的表达其实不是一对一的映射。不是说其他一个语言的词映射成中文就是一定是某个词，要是这样，那翻译器的代码我都能写。很多情况是多对多的，比如同样是表示秋天，英文有fall，有autumn，而fall还有\u0026quot;落\u0026quot;的意思，除了映射秋这个季节本身，还额外附带“萧条“、”伤感“、”衰落”之类的主观情感体验，可能上下文语境稍微有点差异，译文的词就有不同的选择，所以翻译更要求，你要想翻译，首先你要完全读懂，明白作者想表达什么，然后翻译。但这是最理想的情况，翻译不可能不带主观感受，你看到的本来就已经是一个二手的理解了，可能区别不大，也可能面目全非，所以有条件有能力的话看书最好还是看原版\u0026hellip;\n上面是从翻译的角度说，从写作的人的角度来说，也不能说没有责任。我发现文学家写的哲学感悟往往和哲学家写的哲学感悟是不一样的。这是感性和理性的区别。感性放佛天生就带有美学的有色眼镜，而作者可能是最为感性的群体之一，而且美学往往一点都不直白，很隐晦，很“曲折”，很多层的转义。所以作家写一个东西的时候，他不会很直白的去写，而是很扭扭捏捏去描写。比如西西弗神话里面有一句很著名的话，“荒诞感，在随便哪条街上，都会直扑随便哪个人的脸上”。初一听，这个表达好牛逼，但是仔细想，应该是想表达荒诞感每个人都会有的对吧？但是我也不敢很肯定是这个意思。于是，无形中增加了我们理解的成本，甚至误解的概率，当然，这种表达是很“美“的，是文学家所追求的。但是哲学家是很“吝啬”的，他们往往单刀直入，直白的让你怀疑这个东西我所理解的真实是他们想表达的吗，所以我感觉哲学家是很理性的，很有逻辑性的。\n更深层次的 —— 我们可以说都是“巴别塔“惹的祸。圣经有个广为流传的神话，就是古巴比伦人想建造一个能通天的巴别塔，由于大家语言相通，同心协力，高塔直插云端，彷佛没多久真的可以通天了，上帝看到了，就很愤怒，降下灾罚，让人们的语言不再统一，人与人之间难以直接交流，于是最终塔就半途而废了。结合上面说的那些问题，不都是语言的问题吗？语言作为信息的一个载体，两个人要交流，需要一个人写或者说，这个是把自己所想用语言表达出来，这个是表达能力，是编码器，另一个人需要把文字翻译成内心的感受，这个是理解能力，是解码器。编码器和解码器都不是完美的，所以信息就肯定会有失真。所以才会有那么多争吵，很多时候大家表达的东西同一个意思，只不过我编码有问题，或者你解码有问题。同时这也是为什么同一个文化环境下的人之间互相好理解些，因为大家的编码和解码的算法差不多啊，所以误解的概率就小。这还是同一种语言，不同的语言之间还要加了一层“翻译“，那更是痛苦。不得不说，上帝的这个惩罚真是狠，从此没有人能完全理解另一个人，每个人都在信息的孤岛上自说自话\u0026hellip;\n关于语言我隐约还有另一个感觉，现在还不是特别明显，但是已经有了一点迹象。就是我感觉很多时候很多哲学或者终极问题本身，其实就是陷入了语言理解的死循环中。佛法中的一个句式“佛说某某，即非某某，是名某某”，名指的是语言背后的抽象概念，诸子百家就有一个“名家”是专门研究这个的，这个“名”很关键，代表语言所表达的本质。越来越感觉语言是限制我们更深刻理解世界的阻碍。语言是个很高效的理解事物的办法，利于知识的传播，但是表达的准确性是很不够的，以致于我们越来越深陷于语言表面所描绘的描绘的事物。佛学对这一方面的研究很深，对语言很警惕，很多看起来很玄乎的佛学对话其实就是一个意思：我不能说，因为我说的佛法和你理解的佛法肯定不是一个东西，甚至当我说出“佛法”的时候，就错了，佛法本身的定义可能我和你都有差别。“凡所有相,皆是虚妄,若见诸相非相,即见如来”。 然后我又想到了禅宗里面讲究顿悟，刚开始我始终理解不了顿悟是什么感觉，有人说，顿悟的感觉就是：有人一直和你说和牛很好吃，特别好吃，你知道了，你也觉得和牛好吃，但是你真的知道吗？直到有一天你真的吃到了和牛，你才感觉到，真他妈好吃！之前我根本就不知道原来是这种味道！大概顿悟就是这种感觉吧。这或许还是语言的锅，好吃有千万种，我无法通过一个“好吃”，准确表达我的感受\u0026hellip;\u0026hellip;这是永远做不到的事。\n这样越思考就越悲观了，有时候会幻想在圣经的世界里面，上帝发怒之前，人们是怎么一种状态呢，我更愿意相信他们之间连语言都没有\u0026hellip;..或者有一种能百分百交流的语言，那真的就是世界大同了，真这样还有人类做不成的事情？难怪上帝会害怕。 我相信在很遥远的未来，人类会以另一种形态存在，不在以“语言”这种低效的沟通方式交流，或许那时候，各种“孤独感”、“虚无感”、”荒谬感“就会消失吧。\n"
            }
    
        ,
            {
                "id": 11,
                "href": "https://schecterdamien.github.io/posts/2018/interval-tree/",
                "title": "判断多个区间是否有重叠",
                "section": "posts",
                "date" : "2018.10.10",
                "body": " 今天遇到个需求，大致意思是前端给我一堆商品按照阶梯定价的规则，比如订单数为0-200，价格是10块，订单数200-300，价格是8块……简化的数据结构是这样的：\n[ { \u0026#34;min_orders\u0026#34;: 0, \u0026#34;max_orders\u0026#34;: 200, \u0026#34;price\u0026#34;: 10 }, { \u0026#34;min_orders\u0026#34;: 200, \u0026#34;max_orders\u0026#34;: 300, \u0026#34;price\u0026#34;: 8 }, { \u0026#34;min_orders\u0026#34;: 400, \u0026#34;max_orders\u0026#34;: 500, \u0026#34;price\u0026#34;: 7 } ] 我需要对前端传的数据做校验，其中有一部分就是不同阶的上下界不能有交叉（前端给的阶梯数据不一定有序），比如有0-200的阶梯，如果再有100-300的阶梯那这个数据就有问题，因为没法定价。抽象出来问题其实就是判断多个区间（可能不连续）是否有重叠。\n初一看，这个问题其实很简单，两个for循环，第一层记住遍历过的区间，第二层把当前区间和之前遍历的区间一个个比较看是否交叉就可以了。这么做当然没问题，但是时间复杂度是O(n^2)，怎么看都觉得应该有更好的解决办法，第一遍的遍历是怎么都省不了的，所以优化到极致也不可能比O(n)低，第二遍其实就是个比较的过程，既然是比较的话，那就有思路了，可以联想到很多类似的问题，本质上和排序问题是差不多的。\n在stackoverflow看到一个相同的问题：search for interval overlap in list of intervals?。里面提到了一个办法：可以先对区间以左端点进行排序，然后再遍历区间，比较当前区间的左端点和上一个区间的右端点，如果当前的左端点比上一个右端点小，那么一定就有重叠的部分。第一遍排序时间复杂度是O(nlogn)，第二遍遍历时间复杂度是O(n)，所以总体的还是O(nlogn)，比如：\n[(4,6), (7,9), (1,5), (6,7)] 排序完之后是：\n[(1,5), (4,6), (6,7), (7,9)] 然后进行遍历比较，遍历到第二个区间的时候，左端点是4，比上个区间的右端点5要小，所以肯定有重叠的部分。\n第二种办法是构建区间树，上面说的效率最低的那种解决办法，第二层for循环是比较，既然是比较，那么就可以通过树这种结构来提高比较的效率，而不用和前面所有区间进行比较，所以很自然就想到可以构建一个二叉排序树，树的叶节点是每个区间。同时，树的查询效率和树的深度是有关系的，所以构建一个相对平衡的二叉排序树也能进一步提高效率，比如红黑树。算法导论上介绍了这种数据结构，节点是区间的红黑树——区间树。\n红黑树实现起来还是很麻烦的，找了一圈发现github上有现成的轮子——intervaltree，使用非常简单：\n\u0026gt;\u0026gt;\u0026gt; from intervaltree import Interval, IntervalTree \u0026gt;\u0026gt;\u0026gt; tree = IntervalTree() \u0026gt;\u0026gt;\u0026gt; iv = Interval(4, 7) \u0026gt;\u0026gt;\u0026gt; tree.add(iv) \u0026gt;\u0026gt;\u0026gt; target_iv = Interval(5, 8) \u0026gt;\u0026gt;\u0026gt; tree.overlaps(target_iv) True \u0026gt;\u0026gt;\u0026gt; target_iv_2 = Interval(7, 10) \u0026gt;\u0026gt;\u0026gt; tree.overlaps(target_iv_2) False 更多用法可以参考intervaltree · PyPI\n"
            }
    
        ,
            {
                "id": 12,
                "href": "https://schecterdamien.github.io/posts/2018/first-post/",
                "title": "我的第一篇博客",
                "section": "posts",
                "date" : "2018.09.19",
                "body": "折腾博客时的一些感想 折腾了好久，博客终于搭出个大概，有个能看的样子，本来用github+hexo就可以很简单搞定的问题，为什么会浪费这么多时间呢，因为一刚开始想的是自己独立建站，完全自己维护。\n首先，得有个服务器吧，还要有个域名吧。要存文章，tag，评论什么的肯定还要数据库吧，postgresql这么先进，就他吧。后端就用熟悉的flask吧，貌似最近还出了个flask-rest，可以自动生成restful风格的接口，嗯，拿来用用学习下，源码好像不多，要不趁机都看看。部署需要的工具链gunicorn、supervisor、nginx这几个肯定是要吧。对了，还有前端，正好学学前端比较火的框架，就vue吧，主要是比react简单一点，现在不都流行前后端完全分离吗，再小的项目也要有个好的架构啊，不然以后拓展就麻烦了！那就再加个node做中间层转发。好像差不多，对了还要做好安全方面的措施，还有容灾备份啊，而且博客最重要就是页面的设计，这个得好好参考下，是不是要买本设计的书看看…………\n结果，最后就是拖了几个月，就买了服务器、域名、设计了表，其他的一直无限期拖延。仔细想想，貌似这是我一直以来的毛病，分析这个过程，又引出了更多的感想。\n为什么要写博客 为什么要写博客，因为很多知识需要沉淀下来，需要“持久化”，人的大脑是快，就像内存，但是容量有限，很多知识不及时记下来的话，就会丢失，那其实学了和没学一样，对自身技术的进步不利。另一方面，想法也是一样，想法不沉淀下来，一闪而过，其实也相当于没出现，写下来也有助于思考，写出来的东西永远都是思考过一遍的，自我加工的。更重要的是，如果不经常写，那这种写的能力就会退化，到了最后内心澎湃万千，下笔或出口都平平淡淡，甚至会错位。那，其实对我来说，重要是要写东西，而不是使劲折腾怎么搭建博客，当然博客漂亮对我来说也重要，别人看着舒服，我自己写着也开心，但是现在在这上面浪费了太多的时间，以至最终什么都没写，实在是本末倒置。\n方法论 做事情，方法论很重要，我需要的是尽快搭建起一个博客可以写东西，但是上面的方案里面，vue以及页面设计我完全不熟，在这上面卡的时间是最多的。仔细想，我其实是在搭博客的过程中掺杂了很多其他的期望，比如能借此学习到很多新的技术，但是没有仔细思考可能付出的成本，在构想方案的时候我并没有意识到这点，于是无形中提高了门槛，最终又没有一个得到适当的正反馈，导致一再拖延（缺少正反馈是所有拖延的主要原因），所以这个做事情的方法论是有问题的，我应该是先用自己熟悉的技术，自己掌握的住的来快速实现一版，迅速看到效果，得到一个正反馈，然后再反复迭代优化。而且搭建博客和学习新技术其实是两件事，但是我却当成了一件事来做。当然，如果能hold住，那两者可以兼得，这也源于自己没有正确的评估成本。\n坚持 一直觉得时间的力量是很强大的，能让渺小变得伟大。一件很小的事情能够坚持做很久（比如几十年如一日的每天坚持跑步）那比在短时间内完成让人惊讶的事情（比如骑行西藏、突击熬夜复习得满分）难度更大，更显的伟大。其实这不是我第一个博客，之前还有个博客，最后死于没有坚持。我知道这很难，所以我不打算定个计划说每周一定要更新几篇，也许我会几周不写，也可能感觉来了一天写几篇，我并没有赋予博客其他的意义和目的性，也不想达成一个每天都坚持写博客的伟大成就，不过放在更广的时间维度上来看，这事我一直在坚持做，写的也是我想写的，最后也没法放弃，或许会让我觉得自己很厉害吧，哈哈。\n"
            }
    
]
